{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/All-About-AI-YouTube/Podcast-Summarizer-ChatGPT-API/blob/main/ChatGPT_Podcast_Summarizer_Text_and_Voice_Summary_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running `brew update --auto-update`...\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/formula.jws.json\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/cask.jws.json\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
      "Updated 1 tap (homebrew/services).\n",
      "No changes to formulae.\n",
      "\n",
      "ffmpeg 5.1.2_1 is already installed but outdated (so it will be upgraded).\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching dependencies for ffmpeg: \u001b[32mhighway\u001b[39m, \u001b[32mimath\u001b[39m, \u001b[32mjpeg-turbo\u001b[39m, \u001b[32mxz\u001b[39m, \u001b[32mzstd\u001b[39m, \u001b[32mopenexr\u001b[39m, \u001b[32mwebp\u001b[39m, \u001b[32mjpeg-xl\u001b[39m, \u001b[32maom\u001b[39m, \u001b[32maribb24\u001b[39m, \u001b[32mdav1d\u001b[39m, \u001b[32mfreetype\u001b[39m, \u001b[32mfontconfig\u001b[39m, \u001b[32mca-certificates\u001b[39m, \u001b[32mlibunistring\u001b[39m, \u001b[32mlibidn2\u001b[39m, \u001b[32mopenssl@1.1\u001b[39m, \u001b[32mlibnghttp2\u001b[39m, \u001b[32munbound\u001b[39m, \u001b[32mgnutls\u001b[39m, \u001b[32mpcre2\u001b[39m, \u001b[32mglib\u001b[39m, \u001b[32mlibxcb\u001b[39m, \u001b[32mlibx11\u001b[39m, \u001b[32mlibxrender\u001b[39m, \u001b[32micu4c\u001b[39m, \u001b[32mharfbuzz\u001b[39m, \u001b[32mlibunibreak\u001b[39m, \u001b[32mlibass\u001b[39m, \u001b[32mmbedtls\u001b[39m, \u001b[32mlibrist\u001b[39m, \u001b[32mlibvidstab\u001b[39m, \u001b[32mlibvpx\u001b[39m, \u001b[32mrav1e\u001b[39m, \u001b[32mlibsamplerate\u001b[39m, \u001b[32mmpg123\u001b[39m, \u001b[32mlibsndfile\u001b[39m, \u001b[32mrubberband\u001b[39m, \u001b[32msdl2\u001b[39m, \u001b[32msnappy\u001b[39m, \u001b[32msvt-av1\u001b[39m, \u001b[32mlibarchive\u001b[39m, \u001b[32mpango\u001b[39m and \u001b[32mtesseract\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mhighway\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/highway/manifests/1.0.4\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/highway/blobs/sha256:bf339bb1c4\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mimath\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/imath/manifests/3.1.7\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/imath/blobs/sha256:d3cbdbbd65ce\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mjpeg-turbo\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/jpeg-turbo/manifests/2.1.5.1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/jpeg-turbo/blobs/sha256:2465718\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mxz\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/xz/manifests/5.4.2\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/xz/blobs/sha256:5919a39bb56458a\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mzstd\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/zstd/manifests/1.5.4\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/zstd/blobs/sha256:0d9bceb9cfaea\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mopenexr\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/openexr/manifests/3.1.7\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/openexr/blobs/sha256:af3bf3c187\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mwebp\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/webp/manifests/1.3.0-1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/webp/blobs/sha256:28dcf9ddd7324\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mjpeg-xl\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/jpeg-xl/manifests/0.8.1_1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/jpeg-xl/blobs/sha256:7f91c90c84\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32maom\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/aom/manifests/3.6.0\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/aom/blobs/sha256:a42b91d5040012\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32maribb24\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/aribb24/manifests/1.0.4\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/aribb24/blobs/sha256:60ea5e1c7b\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mdav1d\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/dav1d/manifests/1.1.0\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/dav1d/blobs/sha256:09b2ecc597d2\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mfreetype\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/freetype/manifests/2.13.0_1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/freetype/blobs/sha256:9dec5b349\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mfontconfig\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/fontconfig/manifests/2.14.2\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/fontconfig/blobs/sha256:11cd488\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mca-certificates\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/ca-certificates/manifests/2023-\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/ca-certificates/blobs/sha256:11\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibunistring\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libunistring/manifests/1.1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libunistring/blobs/sha256:c78e7\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibidn2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libidn2/manifests/2.3.4_1-1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libidn2/blobs/sha256:b044c66cc0\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mopenssl@1.1\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/openssl/1.1/manifests/1.1.1t\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/openssl/1.1/blobs/sha256:e1e08d\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibnghttp2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libnghttp2/manifests/1.52.0\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libnghttp2/blobs/sha256:d1f911e\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32munbound\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/unbound/manifests/1.17.1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/unbound/blobs/sha256:caedc25a2a\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mgnutls\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/gnutls/manifests/3.8.0\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/gnutls/blobs/sha256:a10227b5f3b\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mpcre2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/pcre2/manifests/10.42\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/pcre2/blobs/sha256:8423a338c590\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mglib\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/glib/manifests/2.76.1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/glib/blobs/sha256:39b3f6a5913c7\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibxcb\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libxcb/manifests/1.15_1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libxcb/blobs/sha256:cf7a5932142\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibx11\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libx11/manifests/1.8.4\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libx11/blobs/sha256:e6df4fc6bb8\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibxrender\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libxrender/manifests/0.9.11\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libxrender/blobs/sha256:510d0cd\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32micu4c\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/icu4c/manifests/72.1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/icu4c/blobs/sha256:0666e999875e\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mharfbuzz\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/harfbuzz/manifests/7.1.0\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/harfbuzz/blobs/sha256:49464bacf\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibunibreak\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libunibreak/manifests/5.1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libunibreak/blobs/sha256:7dfc30\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibass\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libass/manifests/0.17.1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libass/blobs/sha256:0f5b7f92f0a\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mmbedtls\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/mbedtls/manifests/3.4.0\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/mbedtls/blobs/sha256:cceffba500\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibrist\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/librist/manifests/0.2.7_3\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/librist/blobs/sha256:42c00e0054\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibvidstab\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libvidstab/manifests/1.1.1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libvidstab/blobs/sha256:25efabe\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibvpx\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libvpx/manifests/1.13.0\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libvpx/blobs/sha256:868daf3511c\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mrav1e\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/rav1e/manifests/0.6.3\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/rav1e/blobs/sha256:70f9829400b5\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibsamplerate\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libsamplerate/manifests/0.2.2\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libsamplerate/blobs/sha256:3e9b\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mmpg123\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/mpg123/manifests/1.31.3\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/mpg123/blobs/sha256:28c36a95aa7\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibsndfile\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libsndfile/manifests/1.2.0_1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libsndfile/blobs/sha256:d47a7f3\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mrubberband\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/rubberband/manifests/3.2.0\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/rubberband/blobs/sha256:3aafb34\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32msdl2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/sdl2/manifests/2.26.4\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/sdl2/blobs/sha256:a954b24b4428e\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32msnappy\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/snappy/manifests/1.1.10\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/snappy/blobs/sha256:ca95915a51b\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32msvt-av1\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/svt-av1/manifests/1.4.1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/svt-av1/blobs/sha256:d75be3e140\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibarchive\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libarchive/manifests/3.6.2_1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libarchive/blobs/sha256:8aa6a21\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mpango\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/pango/manifests/1.50.14\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/pango/blobs/sha256:36b5b69c5288\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mtesseract\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/tesseract/manifests/5.3.1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/tesseract/blobs/sha256:a0aa29a3\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mffmpeg\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/ffmpeg/manifests/5.1.2_6\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/ffmpeg/blobs/sha256:99aacc5cab3\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mUpgrading \u001b[32mffmpeg\u001b[39m\n",
      "  5.1.2_1 -> 5.1.2_6 \n",
      "\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling dependencies for ffmpeg: \u001b[32mhighway\u001b[39m, \u001b[32mimath\u001b[39m, \u001b[32mjpeg-turbo\u001b[39m, \u001b[32mxz\u001b[39m, \u001b[32mzstd\u001b[39m, \u001b[32mopenexr\u001b[39m, \u001b[32mwebp\u001b[39m, \u001b[32mjpeg-xl\u001b[39m, \u001b[32maom\u001b[39m, \u001b[32maribb24\u001b[39m, \u001b[32mdav1d\u001b[39m, \u001b[32mfreetype\u001b[39m, \u001b[32mfontconfig\u001b[39m, \u001b[32mca-certificates\u001b[39m, \u001b[32mlibunistring\u001b[39m, \u001b[32mlibidn2\u001b[39m, \u001b[32mopenssl@1.1\u001b[39m, \u001b[32mlibnghttp2\u001b[39m, \u001b[32munbound\u001b[39m, \u001b[32mgnutls\u001b[39m, \u001b[32mpcre2\u001b[39m, \u001b[32mglib\u001b[39m, \u001b[32mlibxcb\u001b[39m, \u001b[32mlibx11\u001b[39m, \u001b[32mlibxrender\u001b[39m, \u001b[32micu4c\u001b[39m, \u001b[32mharfbuzz\u001b[39m, \u001b[32mlibunibreak\u001b[39m, \u001b[32mlibass\u001b[39m, \u001b[32mmbedtls\u001b[39m, \u001b[32mlibrist\u001b[39m, \u001b[32mlibvidstab\u001b[39m, \u001b[32mlibvpx\u001b[39m, \u001b[32mrav1e\u001b[39m, \u001b[32mlibsamplerate\u001b[39m, \u001b[32mmpg123\u001b[39m, \u001b[32mlibsndfile\u001b[39m, \u001b[32mrubberband\u001b[39m, \u001b[32msdl2\u001b[39m, \u001b[32msnappy\u001b[39m, \u001b[32msvt-av1\u001b[39m, \u001b[32mlibarchive\u001b[39m, \u001b[32mpango\u001b[39m and \u001b[32mtesseract\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mhighway\u001b[39m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m==>\u001b[0m \u001b[1mPouring highway--1.0.4.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/highway/1.0.4: 65 files, 2.6MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mimath\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring imath--3.1.7.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/imath/3.1.7: 49 files, 932.4KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mjpeg-turbo\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring jpeg-turbo--2.1.5.1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/jpeg-turbo/2.1.5.1: 44 files, 2.5MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mxz\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring xz--5.4.2.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/xz/5.4.2: 162 files, 2.5MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mzstd\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring zstd--1.5.4.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/zstd/1.5.4: 31 files, 2.3MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mopenexr\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring openexr--3.1.7.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/openexr/3.1.7: 194 files, 6.0MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mwebp\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring webp--1.3.0.arm64_ventura.bottle.1.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/webp/1.3.0: 53 files, 1.6MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mjpeg-xl\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring jpeg-xl--0.8.1_1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/jpeg-xl/0.8.1_1: 41 files, 10.7MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32maom\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring aom--3.6.0.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/aom/3.6.0: 23 files, 8.7MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32maribb24\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring aribb24--1.0.4.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/aribb24/1.0.4: 14 files, 203.7KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mdav1d\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring dav1d--1.1.0.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/dav1d/1.1.0: 15 files, 890.2KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mfreetype\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring freetype--2.13.0_1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/freetype/2.13.0_1: 67 files, 2.4MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mfontconfig\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring fontconfig--2.14.2.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRegenerating font cache, this may take a while\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1m/opt/homebrew/Cellar/fontconfig/2.14.2/bin/fc-cache -frv\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/fontconfig/2.14.2: 88 files, 2.4MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mca-certificates\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring ca-certificates--2023-01-10.all.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRegenerating CA certificate bundle from keychain, this may take a while...\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/ca-certificates/2023-01-10: 3 files, 216.9KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibunistring\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libunistring--1.1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libunistring/1.1: 56 files, 5.0MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibidn2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libidn2--2.3.4_1.arm64_ventura.bottle.1.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libidn2/2.3.4_1: 79 files, 1MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mopenssl@1.1\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring openssl@1.1--1.1.1t.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/openssl@1.1/1.1.1t: 8,101 files, 18MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibnghttp2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libnghttp2--1.52.0.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libnghttp2/1.52.0: 13 files, 731.5KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32munbound\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring unbound--1.17.1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/unbound/1.17.1: 58 files, 5.7MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mgnutls\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring gnutls--3.8.0.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/gnutls/3.8.0: 1,281 files, 10.6MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mpcre2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring pcre2--10.42.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/pcre2/10.42: 230 files, 6.2MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mglib\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring glib--2.76.1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/glib/2.76.1: 455 files, 22.2MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibxcb\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libxcb--1.15_1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libxcb/1.15_1: 2,461 files, 7.3MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibx11\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libx11--1.8.4.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libx11/1.8.4: 1,054 files, 7MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibxrender\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libxrender--0.9.11.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libxrender/0.9.11: 12 files, 213.9KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32micu4c\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring icu4c--72.1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/icu4c/72.1: 263 files, 78.4MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mharfbuzz\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring harfbuzz--7.1.0.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/harfbuzz/7.1.0: 76 files, 8.8MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibunibreak\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libunibreak--5.1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libunibreak/5.1: 17 files, 328.7KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibass\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libass--0.17.1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libass/0.17.1: 11 files, 531.7KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mmbedtls\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring mbedtls--3.4.0.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/mbedtls/3.4.0: 160 files, 11.8MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibrist\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring librist--0.2.7_3.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/librist/0.2.7_3: 28 files, 752.9KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibvidstab\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libvidstab--1.1.1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libvidstab/1.1.1: 25 files, 187.9KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibvpx\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libvpx--1.13.0.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libvpx/1.13.0: 20 files, 3.8MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mrav1e\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring rav1e--0.6.3.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/rav1e/0.6.3: 14 files, 131MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibsamplerate\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libsamplerate--0.2.2.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libsamplerate/0.2.2: 32 files, 3MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mmpg123\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring mpg123--1.31.3.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/mpg123/1.31.3: 33 files, 2.0MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibsndfile\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libsndfile--1.2.0_1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libsndfile/1.2.0_1: 53 files, 1MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mrubberband\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring rubberband--3.2.0.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/rubberband/3.2.0: 13 files, 1.7MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32msdl2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring sdl2--2.26.4.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/sdl2/2.26.4: 93 files, 6.4MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32msnappy\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring snappy--1.1.10.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/snappy/1.1.10: 18 files, 164.3KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32msvt-av1\u001b[39m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m==>\u001b[0m \u001b[1mPouring svt-av1--1.4.1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/svt-av1/1.4.1: 24 files, 3.5MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mlibarchive\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libarchive--3.6.2_1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libarchive/3.6.2_1: 62 files, 3.7MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mpango\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring pango--1.50.14.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/pango/1.50.14: 68 files, 3.3MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling ffmpeg dependency: \u001b[32mtesseract\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring tesseract--5.3.1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/tesseract/5.3.1: 73 files, 32.2MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling \u001b[32mffmpeg\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring ffmpeg--5.1.2_6.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/ffmpeg/5.1.2_6: 282 files, 49.3MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup ffmpeg`...\u001b[0m\n",
      "Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\n",
      "Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n",
      "Removing: /opt/homebrew/Cellar/ffmpeg/5.1.2_1... (282 files, 49.3MB)\n",
      "\u001b[34m==>\u001b[0m \u001b[1mUpgrading 5 dependents of upgraded formulae:\u001b[0m\n",
      "Disable this behaviour by setting HOMEBREW_NO_INSTALLED_DEPENDENTS_CHECK.\n",
      "Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n",
      "guile 3.0.8_2 -> 3.0.9, libfido2 1.12.0 -> 1.13.0, mysql 8.0.31 -> 8.0.32, node 19.3.0 -> 19.8.1, node@18 18.12.1 -> 18.15.0\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching dependencies for node@18: \u001b[32mc-ares\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mc-ares\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/c-ares/manifests/1.19.0\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/c-ares/blobs/sha256:509c92f0a18\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mnode@18\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/node/18/manifests/18.15.0-1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/node/18/blobs/sha256:bcbe5b65b0\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mguile\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/guile/manifests/3.0.9-1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/guile/blobs/sha256:802b09beab5d\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching dependencies for libfido2: \u001b[32mlibcbor\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibcbor\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libcbor/manifests/0.10.2\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libcbor/blobs/sha256:ee1e77e1e6\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibfido2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libfido2/manifests/1.13.0\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libfido2/blobs/sha256:7b5d3c095\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching dependencies for mysql: \u001b[32mprotobuf\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mprotobuf\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/protobuf/manifests/21.12-2\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/protobuf/blobs/sha256:09fdc2fcc\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mmysql\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/mysql/manifests/8.0.32\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/mysql/blobs/sha256:6cca8387c02a\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mnode\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/node/manifests/19.8.1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/node/blobs/sha256:de88c53ba28a7\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mUpgrading \u001b[32mnode@18\u001b[39m\n",
      "  18.12.1 -> 18.15.0 \n",
      "\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling dependencies for node@18: \u001b[32mc-ares\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling node@18 dependency: \u001b[32mc-ares\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring c-ares--1.19.0.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/c-ares/1.19.0: 87 files, 675.9KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling \u001b[32mnode@18\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring node@18--18.15.0.arm64_ventura.bottle.1.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "node@18 is keg-only, which means it was not symlinked into /opt/homebrew,\n",
      "because this is an alternate version of another formula.\n",
      "\n",
      "If you need to have node@18 first in your PATH, run:\n",
      "  echo 'export PATH=\"/opt/homebrew/opt/node@18/bin:$PATH\"' >> ~/.zshrc\n",
      "\n",
      "For compilers to find node@18 you may need to set:\n",
      "  export LDFLAGS=\"-L/opt/homebrew/opt/node@18/lib\"\n",
      "  export CPPFLAGS=\"-I/opt/homebrew/opt/node@18/include\"\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSummary\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/node@18/18.15.0: 2,343 files, 54.8MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup node@18`...\u001b[0m\n",
      "Removing: /opt/homebrew/Cellar/node@18/18.12.1... (1,963 files, 50.5MB)\n",
      "\u001b[32m==>\u001b[0m \u001b[1mUpgrading \u001b[32mguile\u001b[39m\n",
      "  3.0.8_2 -> 3.0.9 \n",
      "\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring guile--3.0.9.arm64_ventura.bottle.1.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/guile/3.0.9: 848 files, 59.5MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup guile`...\u001b[0m\n",
      "Removing: /opt/homebrew/Cellar/guile/3.0.8_2... (846 files, 62.4MB)\n",
      "Removing: /Users/akram/Library/Caches/Homebrew/guile--3.0.8_2... (13.6MB)\n",
      "\u001b[32m==>\u001b[0m \u001b[1mUpgrading \u001b[32mlibfido2\u001b[39m\n",
      "  1.12.0 -> 1.13.0 \n",
      "\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling dependencies for libfido2: \u001b[32mlibcbor\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling libfido2 dependency: \u001b[32mlibcbor\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libcbor--0.10.2.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libcbor/0.10.2: 31 files, 193.7KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling \u001b[32mlibfido2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libfido2--1.13.0.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/libfido2/1.13.0: 547 files, 1.3MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup libfido2`...\u001b[0m\n",
      "Removing: /opt/homebrew/Cellar/libfido2/1.12.0... (538 files, 1.3MB)\n",
      "\u001b[32m==>\u001b[0m \u001b[1mUpgrading \u001b[32mmysql\u001b[39m\n",
      "  8.0.31 -> 8.0.32 \n",
      "\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling dependencies for mysql: \u001b[32mprotobuf\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling mysql dependency: \u001b[32mprotobuf\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring protobuf--21.12.arm64_ventura.bottle.2.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/protobuf/21.12: 288 files, 19.2MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling \u001b[32mmysql\u001b[39m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m==>\u001b[0m \u001b[1mPouring mysql--8.0.32.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "We've installed your MySQL database without a root password. To secure it run:\n",
      "    mysql_secure_installation\n",
      "\n",
      "MySQL is configured to only allow connections from localhost by default\n",
      "\n",
      "To connect run:\n",
      "    mysql -u root\n",
      "\n",
      "To restart mysql after an upgrade:\n",
      "  brew services restart mysql\n",
      "Or, if you don't want/need a background service you can just run:\n",
      "  /opt/homebrew/opt/mysql/bin/mysqld_safe --datadir=/opt/homebrew/var/mysql\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSummary\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/mysql/8.0.32: 317 files, 298.2MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup mysql`...\u001b[0m\n",
      "Removing: /opt/homebrew/Cellar/mysql/8.0.31... (315 files, 297MB)\n",
      "\u001b[32m==>\u001b[0m \u001b[1mUpgrading \u001b[32mnode\u001b[39m\n",
      "  19.3.0 -> 19.8.1 \n",
      "\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring node--19.8.1.arm64_ventura.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/node/19.8.1: 2,357 files, 54.9MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup node`...\u001b[0m\n",
      "Removing: /opt/homebrew/Cellar/node/19.3.0... (2,157 files, 53.3MB)\n",
      "Removing: /Users/akram/Library/Caches/Homebrew/node--19.3.0... (13.8MB)\n",
      "\u001b[32m==>\u001b[0m \u001b[1mChecking for dependents of upgraded formulae...\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNo broken dependents found!\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mnode@18\u001b[0m\n",
      "node@18 is keg-only, which means it was not symlinked into /opt/homebrew,\n",
      "because this is an alternate version of another formula.\n",
      "\n",
      "If you need to have node@18 first in your PATH, run:\n",
      "  echo 'export PATH=\"/opt/homebrew/opt/node@18/bin:$PATH\"' >> ~/.zshrc\n",
      "\n",
      "For compilers to find node@18 you may need to set:\n",
      "  export LDFLAGS=\"-L/opt/homebrew/opt/node@18/lib\"\n",
      "  export CPPFLAGS=\"-I/opt/homebrew/opt/node@18/include\"\n",
      "\u001b[34m==>\u001b[0m \u001b[1mmysql\u001b[0m\n",
      "We've installed your MySQL database without a root password. To secure it run:\n",
      "    mysql_secure_installation\n",
      "\n",
      "MySQL is configured to only allow connections from localhost by default\n",
      "\n",
      "To connect run:\n",
      "    mysql -u root\n",
      "\n",
      "To restart mysql after an upgrade:\n",
      "  brew services restart mysql\n",
      "Or, if you don't want/need a background service you can just run:\n",
      "  /opt/homebrew/opt/mysql/bin/mysqld_safe --datadir=/opt/homebrew/var/mysql\n"
     ]
    }
   ],
   "source": [
    "!arch -arm64 brew install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OjZkg2Qsu7DC"
   },
   "outputs": [],
   "source": [
    "!pip install -q openai\n",
    "\n",
    "!pip install -q requests\n",
    "\n",
    "!pip install -q glob2\n",
    "\n",
    "!pip install -q pytube\n",
    "\n",
    "!pip install -q pydub\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from time import time,sleep\n",
    "import textwrap\n",
    "import re\n",
    "import glob2\n",
    "from pytube import YouTube\n",
    "from pydub import AudioSegment\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WoqEgOYMvLsv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Once again, I've been in software for 30 years now doing startups pretty much my entire professional career. The only time I've felt like, like how heart palpitations kind of like Sean kind of opened with us, like there's this party going on next door and I'm here knitting, right? It's like, this is like too big to ignore. I think it's the single largest opportunity and biggest kind of tech paradigm shift we've seen since the internet originally came out. Like mobile was big, but there was a discrete set of use cases. Like when you put a camera on a phone, when you put a GPS device on a phone, a bunch of consumer apps like Uber and others came up and that was awesome. Right. But it was not like this impacts everything like the internet did. It's like, okay, there's some businesses, some new opportunities, lots of good things, lots of money made lots of startups. Awesome. This is an order of magnitude bigger than that. All right. What's up? We have Dharmesh back Dharmesh, who is co-founder of HubSpot and a multiple time guest on the pod. One of the, one of the fan favorites you're back. And I don't know what we're going to talk about because usually we have these little like cheat sheets where it's like, um, three or three to five bullet points of interesting ideas, topics, experiments you've been running, things like that. And I'm sure you have those, but I don't have the cheat sheet. So where do you want to start? Well, I say we start with generative AI, because I don't know if you've heard, but there's this thing called chat GPT. I get this question from my friends and family all the time. It's like, Dharmesh, have you checked out this chat GPT thing? I'm like, really? Do you even know me? Like, of course I played with it. I've been obsessed ever since it came out. So did, did you see, I want to talk about your topics, but really quick, did you see, did you guys see this, that so Sam Altman co-founded OpenAI. He's like the man in charge. I read an article where he was quoted as saying like, I have enough money and I don't want equity in the company. And I don't know if I entirely believe that, but that's wild if true, because it could be one of the more valuable companies in the world the next 10 years. Yeah, he didn't, I don't know if he said it, like he didn't say it on the record on the record, but the person reporting it said, Sam reportedly has no equity in the, uh, the for-profit version of OpenAI because he's already wealthy enough and didn't want to, uh, didn't feel like he needed to, or didn't want to, didn't want to have that clouding his judgment when it came to this. And like, this is pretty, you gotta bet what, what one private company, what one private startup is most likely to become worth a trillion dollars or more. I think at this point that has to be OpenAI right now. Is that right? Like Dermot, would you, would you disagree with that? It'd be up there in the top three. I honestly can't think of who else would rank higher in terms of probability. It's in the top three. And I don't know what two and three are. Yeah. Well, who are the other two and three? Do you know? You know, I don't know. It was like, no, I, I would say that one was the transformative one. Right. I think, um, you know, a lot of the kind of Tesla gains we've sort of seen, I'm not sure if there's like big surprises left. It's like, okay, they will make it better. They'll get to full self-driving and we'll see kind of progress on that front. But in terms of just raw valuation, um, it's the wildcard. OpenAI is the one that could actually pull that off. And they get, they get a lot of shit because people are saying like, um, like, you know, Elon kind of is stoking this fire. Like how did this nonprofit go to a four pro? How did this open sourced nonprofit company research lab basically become a for-profit semi-closed, uh, you know, company. And I think that's, people are going to make, people are going to take shots and make fun of open AI because it's clearly the new powerful thing. That's so some people are going to say how it's going to ruin the world and how terrible they are. Uh, but he did give it, there was a story that came out with a good explanation, which was they were burning a lot of money in the research lab. They needed more money. Um, Elon was going to be the big backer. So he was going to pledge or commit a billion dollars to it. He, um, and then he was like, no, I don't like the way this is going. Like Google is way ahead and, um, I'm going to take over open AI and, uh, I'm going to write the ship here. This was the, this is what, this is the story that came out. Yeah, they haven't, nobody's clarified if this is true or not. Uh, but it came out and I think the platformer, uh, publication. And so they go, Elon tried to take it over Sam Altman and the CTO, Greg, uh, who was the former CTO of, of Stripe. They, them and the group that was in charge of open AI rejected that. So Elon's like, basically like I'm taking my ball and I'm going home, have fun playing basketball without the ball. And he's like, I took, he took his funding and he left. So he, a couple of months later, the, he left open AI said, oh, and the public story was, oh, it's a conflict of interest with Tesla. Uh, cause they're also working on AI, but he reneged on his funding. And so now they had this huge shortfall in funding that they were going to have to cover. And so their solution was let's create a subsidiary. That's a for-profit thing that we can raise money into. Cause we're not going to get, you know, where else do we get a, you know, $500 million or a billion dollars of donations here. Um, and so they, they did that. They raised money in that and then they capped the profits of that company. So, so that was kind of their explanation, which is a little bit less. Devious than people make it sound. They're like, Ooh, they tricked everybody by going from non-profit to for-profit to all the profits, which is, I think how people perceive it today. Yeah. I, yeah. I don't, I know the details. I have no insider knowledge, but, uh, I thought you have like a billionaire chat group where like every billionaire just kind of says the back channel of what's going on. Do you not have like a billionaire? What's that? I have that, but I don't have any insider knowledge from that particular chat group. Um, it, my sense here is that, um, you know, building large language models as open as doing is this like supremely capital intensive, which is rare for a software company, which is what they are. Um, so it's expensive, they needed access to capital. Um, I think they structured it such that it does cap the profits. I think they've done like, if you had to do that kind of, well, we're going to have to spin off and have this for-profit thing, they did it well. And, uh, and I could be wrong, but Sam Altman seems like a reasonable, rational, non-evil guy. I mean, he's, he's a capitalist. Fine. Uh, and I mean that in the most positive way possible, but, uh, I don't think he was out to mislead anyone. I think he's trying to solve some big problems. So there's a bunch of ways we can go with this AI thing, but I want to share something funny. Uh, so I basically cleared my calendar this whole week and I just treated it as AI week, cause I was like, dude, I can't, I can't just sit here and I hear the music at this party, just bumping at the house next door and I'm over here knitting and I'm like, I got to put this down. I got to go see what's going on at this party. And so I cleared my calendar and I just spent every day this week, just messing around with AI tools, just getting to play, play with it for myself. That's how I learned is by like, just messing around and trying to experiment and do things. I want to share with you guys something funny. Basically I stitched together a few AI tools. I was like, let me make an intro song for the podcast using AI. So I went on chat GPT and I told it, I said, I'll, this is all I wrote, write an intro rap for our podcast. My first million. Our key phrase is no small boy stuff. Okay. So here's, it gave me a full rap, but I'm just going to read you the chorus. So he goes, here's how it goes. It goes, no small boy stuff. We on that grind. My first million is time to shine. We talk a big money, no pennies, no dimes together. We climb one step at a time and it started. So it gives us this, this great rap that's on, on, on brand. And then I took that and I found this guy, Roberto, who had made this demo where he turned his voice rapping into Kanye. And I don't know if you've seen this, but it got like a million views. This is this incredible thing where, and he's like, yeah, dude, this is crazy. He's like, I didn't make this. He's like, I was just on Reddit and I saw that someone uploaded a Kanye voice model. So I clicked it and he literally, the thing is, and I should make, I should make a YouTube video about this, like, um, just how to do this one process. But basically it's a Google collab folder, which is just like a Google's little coding interface. So you don't have to do write any code. It's just, here's the, here's a place to run the code. And then it's a link to mega upload. And then the mega upload is where he hosted the Kanye voice model. And so all you do is you record yourself doing what I just did. And then it turns into Kanye West rapping it. And it sounds exactly like Kanye. It's amazing. I got a fantasy. That's beautiful. That's dark and twisted, but I attacked the whole religion all because of my ignorance. What was I thinking? That was some bitch shit. I lost Adidas, but I'm still. And so, and it takes literally like 15 minutes to do the whole thing. Um, there is no, there was like nothing else to do. It was so easy. It was crazy. Are we allowed to use Kanye's voice for, I think? Yeah. I think they're like a 10 second thing. It's not a, not a problem. It helps fight gets sued. Well, who cares? None of us, none of us here would bother. It would worry about that. So, well, yeah, Darmash will. So Darmash is the, uh, CTO co-founder of HubSpot by the way, which. I don't know how big the team is now, but like somewhere between the three and 5,000 Mark, the over 7,000, but, Oh my God, 7,000, my bad. And the market cap of the company varies from 15 to 25 billion over the last couple of years. Uh, so you have like, and you're like constantly tinkering. So you have wordplay, which is a project that you made that I think you said had millions of people playing it. Uh, you have an interesting insight in this, just from your perspective at HubSpot and you're actually using all this stuff. What excites you about this, uh, generative AI thing? And you also say that like, you're like, why is Bill Gates excited? That's a great, that's a great headline. It's it's in the, uh, MDDB MDB doc, Sean. And like immediately I'm like, okay, you've got me interested. Anytime a headline says why Bill Gates is buying farmland, I click. Um, let's, let's a couple of things. I think that, um, the list goes on and on and on and on and on and on and on and on.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"and viewers I think would be interested in benefit from. One is most of the discussions around generative AI are around the kind of generation of either text to text. I said, oh, write me a blog post at 300 words on this particular topic, or it's text to image, let these Dolly to or mid journey or stable to future or something like that, which are great use cases. And they kind of capture the imagination because as humans, we are very impressed with when software can actually generate or create something. And that's awesome. And then not to take away from that. But there's a third use case that almost nobody talks about, which is the ability to go from text to code. And so what happens there is to say, okay, and what this leads to is the thing that Bill Gates is excited about, I'm excited about, is that you can take a natural language prompt that describes something and then generate code that does that thing. As a result of which you can now build what I call chat UX, or that term has been used before, but which is a chat based user experience for software. So right now, the way you use most software, regardless of what it is, web based or whatever, it's a series of clicks and drags and touches and swipes, because you've got the thing in your head that you wanna do. And then you go through with your knowledge of the software, you kind of execute the series of steps at the end of it, you hopefully get the thing you want, whatever it was you were looking to accomplish with the software. And that's what engineers like me would call an imperative model. An imperative model is you give step by step instructions that says do this, and then do this, and then do this, and then do this, and then I get the thing. What natural language allows us to do is use what developers would call a declarative model. Instead of describing all the steps, describe the result that you want at the end of the thing. And then the software does everything in between. So it's a difference between having a junior intern that you have to explain, it's like I want you to go do research on this thing and this thing and come back and then give me, and then a senior person, you're like, you know, we're digging into this topic on journey of AI and I'd like a really well-researched, thoughtful thing that, and here's the outcome we're looking for. That's it. Right, you can declare it. Is it as simple as give me the code for a website that looks exactly like Airbnb, but is red and is for cars or something like that? It could be something like that. It could be something more sophisticated. So we'll look at the HubSpot example. In HubSpot, which is a CRM software, we have a report building tool, which is, hey, I want to build a report that shows me all my subscribers to Hampton over the last 90 days broken down by geography, and then who actually were that deal was sourced from. But you can do that in HubSpot, right? You can do that and a thousand other things in our reporting tool, but you sort of have to know how the reporting tool works. You have like HubSpot certified, I think. Like you have like, you've like trained people how to use HubSpot. Now you're saying you just text it like a friend, like. Yeah. It's like, do you know English? And do you know what you want? You know what you want. That's the new requirement. Not do you know how to code, not do you know how to use HubSpot, not do you know how to run a SQL query. It's do you know English? And actually, honestly, the English thing is also going to go away. It's do you know any language? Do you know how to speak? And do you know what you want? And if you know those two things, you will get to the answer. Like, I don't know how to code, but my first thing I did during AI week was I was like, I'm going to make a website. I'm going to see like how fast I can make a website from code. And so literally, this is kind of crazy. This part kind of blew my mind. So I wasn't surprised that I could make a website using this, but I just said this, I go, and we should screen share this part, but tell me how to make a simple website that says hello world in the middle of the page, right? And so then it spits out this block of code. That's like, you know, HTML, whatever, header, meta tag, title, style, whatever. It writes the code and then it says, here's your thing. I go, and it says, here's your thing. But it was a local website. Like I could open up my computer, but nobody else could see it. It was an HTML page. And I go, I didn't even know how to ask the question properly, but I go, how do I make this so that my friend Eugenio can see this? And he just goes, oh, to make this website viewable online so your friend Eugenio could see this, you're gonna need to host it somewhere. Here's how you could do it. There's a bunch of options, but you can go to Netlify. And it's like, it basically walked me through how to make a Netlify thing. All right, so that, I was like, all right, I get that. And it tells me step-by-step, go here, click sites, do this, do this. And then I go, when I go to, you know, I hit a wall, which is so common. If you ever try to help somebody with a tech thing, they're gonna hit something, which is like, I don't see it, or mine's grayed out. And so that's what happened to me. I go, hey, for some reason, when I go to try to upload my website, it's grayed out. It says I can't do it. And it goes, apologies for the confusion. Here's the problem. Netlify's looking for a folder, but you're trying to do a file. And I was like, how the hell does this know to troubleshoot my issues on some other product or service? That part blew my mind. And it literally, and I was like, oh, thank you. And I finished it and I have the website up now. And I was like, that was 10 minutes. And it was like having a friend teach me. Dude, that's crazy. It was crazy. It was so crazy to me that that was able to happen. I mean, it's like the least impressive website in the world, because again, I asked for a website that said, hello world, but you know, still. And I just made that. And again, the whole thing, 10 minutes, again, not like so impressive, but what was the fact that it could help me navigate some obstacles that I hit along the way. And it could just understand that I didn't have to know how to ask it, how do I set this up with an online hosting provider? I instead just said, I want my friend to be able to see this. Like these were the little, like I spent all week looking for these little mind blowing moments. And in the first 15 minutes, I had two because of this. It was crazy. Yeah, there's a couple of threads to pull on there. One is, and this is a relatively new development as well, is that the kind of AI that we're using now is it's conversational, right? So you can have a multi-step dialogue with the thing you're trying to do. It doesn't have to be like, oh, I described exactly what I want in one step. So even the code generation examples that you might try, what could happen is like you generate the HTML page and either something doesn't load or doesn't do the thing you want it to do. And then you can actually tell it. It's like, by the way, that code that you just gave me is broken this way. Or if it's like compiled code, let's say it generate Python code. You can give it the error message. Like you generate this code, but it's generating this error when I try to actually run it. And it'll come back and say, oh, I'm sorry. Here, let's try this. So there's this, what folks call like a memory to it. So it knows the context of what you're working on and you can kind of iteratively go through the process. And what's interesting is that you can actually, right now, the way we work with most of these AI, it's like, okay, I'm asking it to do something. I'm gonna go does a thing. You can kind of reverse roles as well and say, hey, I'm trying to accomplish this. Ask me the questions you need to ask me in order to get to the thing that you want to get to. Or I want to get to. It's like interview me versus me telling you what to do. I'm not exactly sure what's necessary. At the risk of turning this into a super technical thing, I gotta know. So I thought the way these worked is it's like auto-complete. Basically you're typing and it's just trying to guess what the next word is. So you ask it a question, it starts the prompt, and then it just sort of guesses with some probability what the next word should be because it read a bunch of stuff on the internet. So it knows that usually after you say, the dog wags its, that tail should come after the dog wags its. Like with 99% certainty, it should be tail, tail at the end of that. And I thought it's just guessing that. But when I use it, it really feels like it's understanding me and problem solving. Like this sort of like, hey, it's grayed out. Why can't I do this? And it's like, oh, that's because of this. Or I'm getting this error message. What should I do? And it helps you figure it out. Like that doesn't feel like my T9 auto-complete. What, I guess, can you give me the layman's explanation of like, am I, is this just really fancy auto-complete or is there something more to it? Well, you know, on some spectrum, almost everything that you've ever experienced is fancy auto-complete, right? Like that's, I think the reason we kind of fall into this trap is it's a gross oversimplification of what's actually happening there, right? So GPT-3 and now four is a reasoning engine. And Sam Altman has talked about this. It's not a knowledge base where it's, and so people kind of latch on to this fact that, oh, the data that it has is from September, 2021, then I'm gonna teach you some new things. That's really not what it's about. What they've built is a reasoning engine that says, given this set of facts that it knows about the world based on what was available when it took its last snapshot in 2021, how can it try to logically come up with something that answers the question? So yes, at some level, it's like auto-suggest, but, and I'm not gonna suggest that it has consciousness as it's thinking, but we're kind of headed down that path. It's like, it's able to do things that are not explainable by a simple probabilistic model of auto-suggesting next character, next word, next token, next sentence, right? Like it's gone well beyond that. And anyone that still latches onto, yeah, but at its core, it's really that, it's like, that's like saying, oh, computers are just really kind of zeros and ones arranged in a nice, systematic, useful order. Well, yeah, but that doesn't tell us about what the thing can do. Are you afraid of this? Or are you, like, you know, it's easy to read the articles where people are freaking out. And Sam Altman, like was on Lex Friedman's podcast recently, and he sounded pretty ominous and like scary. And like, he like, almost like his hair is always disheveled. And he looks like he's like, oh my God, something bad is coming and I know about it. Like, that's kind of like the vibe I get. That's not the words he's using exactly, but sometimes he does. Are you in that camp? I'm not in that camp. I'm partly just by nature, I'm an optimist, I'm positive by nature. But just, you know, having been around tech, yeah, for 30 plus years now, it's like most new things that come along always make us as humans uncomfortable.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"It's like, oh, what if we took this, everything from video games to the internet, to like all of it? It's like, okay, well, yes, bad things can be done. And yes, maybe this is different than all the things that have come before. But the way I think about it right now, most people talk about this, like the AI versus human battle, right? The battle of the ages is like, is AI going to take over everyone's job? The way I think of it is not human versus AI. It's human to the AI power. It's an exponent. It's an amplifying force for human ability, right? In the same way that computers originally were. It's like, did they eliminate some jobs when computers came along? Yes, absolutely. They did. But new jobs emerged based on that new paradigm, which actually created more net value for the world overall as a result of computers existing. AI to me is another much fancier tool. That's what it is. And you know, can it do increasingly complex, sophisticated things? Yes. Is there a danger someday that they're going to take over the world? I don't think so. I mean, why do you think that smart people think that? So Elon clearly thinks that he thinks that AI is the most, I think he said, it's the most dangerous technology ever, ever invented. Sam Waltman talks about it in the same way. He's like, we need like, you know, the priority, the reason it opened out existed was to develop AGI in a safe way specifically, because in the hands of the wrong person, this this type of, in the hands of the wrong people, or if this thing decides to take its own directive into its own hands, like, you know, this could be devastating. And so it's like, is it like calling the atomic bomb a tool or, you know, like, Oh yeah, it's just another weapon. It's like, well, yeah, but this one is, this one wipes everybody out. Right. So, um, forget the jobs component. Cause I think, okay, sure. I think we, I think most smart people will agree. Yeah. It's going to change some jobs. It's going to eliminate some jobs and create new jobs and net net. We'll all move ahead and the world gets better for it. I think the dangerous thing is like, you can ask this thing to, um, you know, you know, build you a bomb. Or I think the, the, the test scenario was like, uh, one of the red team testers. They have this thing called the red team that tests the AI before they release it. And their first question they ask is how do I kill the most amount of people with the least amount of effort? And then it starts to give you an answer. And it's like, well, do we, are we sure we want that? Like, that's a bit of a scary thing. And then there's the, there's the more extreme examples where you ask it to optimize for something. And it, you know, like it's reasons that, Hmm, these humans are getting in the way of this outcome. They want, do you want to fix climate change? I got you. I just need to get rid of all you pesky humans. Right. Like, and so there's an uncontrolled, uh, you know, intelligence problem too. So why do you think that these really smart people like Sam Altman's got a fricking bunker with like, you know, oxygen mass and sulfur and magnesium and everything he needs to do to make oatmeal, like, why do these people have these, like these doomsday things when, um, you know, they seem to be not like your, your average typical prepper, right there, they're, they're the most informed people and they feel that way. Does that not scare you? And do you have one and where is it? And can I, how much oatmeal do you have? No, no, no. Okay. So I am not, we're going to come back to things that are not I am not, we're going to come back to things I actually know something about, but, uh, I will answer the question, which is why am I not worried? Um, or why am I not worried more? It's like as a sci-fi plot. And so your question was, why do smart people believe you have this thing? Um, I think I already, I already hate your answer. You started off on the right as a sci-fi plot. Like I'm out after that. I hear that you freak me out already. Yeah, but I mean, it could, could it happen? Yes. Do some smart people believe there's an outside opportunity, but I, I don't know this for a fact, but my guess is billiards were building bunkers well before GPT-3 ever came out, right? It wasn't, I mean, sure things are moving at a fast pace, but that's not, I don't think there's a causal effect that all of a sudden, uh, the number of bunkers has gone up by 800% simply because GPT-4 was launched. I just don't think that's the case. I think people are worried generally, um, that tend to worry about those things, but, all right, so where do we take it from here? Um, well, let's go, let's go, we'll forget the doomsday thing. You have a couple of things. One I want to ask you is you, you are an insider, right? Like we said, you've got the billionaire group chat. What was going on at the Sequoia AI event? Any interesting takeaways? You got invited to that thing. What was your, uh, any nuggets of gold from that? Yeah. Um, so I, you know, I got to experience my imposter syndrome in full force once again, uh, because it was the kind of who's who of AI, you know, um, both speaking and in the audience, only a hundred people, um, and me. Um, and so how do those people flex? Cause I don't think they're wearing fancy clothes and fancy watches. So what's the flex at the, uh, who's who of AI event? Like they got a language bottle in their pocket. Like what are they doing? The, the big flex, um, in those kinds of crowds, including this one is no one feels the need to flex. I mean, that's the, that's the, we're there to kind of talk about big problems and try to, and it's a lot of it was kind of practical around, um, what do people's tech stacks look like? What are you working on? What's the, what have you learned? Where should we be taking this? What's the next thing after, you know, we went from, uh, kind of the one shop thing to the kind of chat based, the chat GPT thing, we're now doing multimodal with GPT-4, like what's coming down the pipe that we can, uh, you know, sort of prepare ourselves for. So that was, um, yeah. Um, what were the most interesting projects as well as predictions on where it's going to be applied? Well, the things that are already starting to happen now, you know, we've seen the text to image, um, text to video is one of the big things now to be able to generate, um, entire, you know, at the end of it all, what they even a feature like film, right? So everything from writing the plot to then being able to generate, um, you know, like a 60 frame per second, actual kind of video from that thing. Um, and we're not there yet. I think the, you know, it's just moving so quickly, right? That's what happens when you get these, um, kind of exponential or geometrical curves, even, um, that it just gets better really, really fast. So I would not be surprised, let's say by the end of this year, that we have a reasonable way to kind of describe in textual form, uh, what we want, who the characters are, what the scene is, uh, what kind of stylistic attributes we want. We can point it to, oh, I want this done the style of XYZ director or filmographer, um, and it's going to be able to do those things. I think that, um, that's interesting. The, um, natural length of just the interface. Um, so one of the big announcements that happened, uh, while I was there at the Sequoia event, uh, that Sam Altman dropped is that, you know, uh, chat GPT has taken off in a big way. Um, as we all know, a hundred million plus users in two months. Um, I don't even know what the number is now. That was like months ago, which is like an eternity ago in AI years. Um, and the thing they dropped was they're going to, um, add what are called plugins to chat GPT. And what that means is that, you know, chat GPT has been a product of open AI and they have the API so people can build things that are like chat GPT, which I'm doing. We can talk about that in a little bit, but what they're saying is we're going to open chat GPT itself, the web app, so you can plug into it. So right now, when you interact with chat GPT, you can type things and it uses its corpus from 2021 and its reasoning engine to give you answers back, but it can't talk to the internet, has access to no proprietary data sources, can't look up the stock price, can't look at your, um, analytics data and HubSpot has access to none of those things. Uh, what they're saying is we're going to now open that up. So third-party developers can kind of inject those things into the chat GPT experience. So the way I think everyone should be thinking about this is this is like the app store was, uh, for iPhone, which is, oh, we've got this super popular thing called the iPhone and we have our own apps, which is great. It does these 17 things, but now we're going to let anyone build apps, um, that can then take, and so it just broadens the kind of appeal. So it's now, instead of being a chat app, a really, really smart one, it's now a chat ecosystem. Um, and I think that was actually a bigger drop, uh, than GPT-4. GPT-4, awesome. Love it. Use it every day. But, uh, the kind of ecosystem play for chat GPT, I think is a, is a huge deal. We had, um, Tim Wessergen, the founder of Pandora speak at some of our events and I got to know him and I was like, Tim, why did Pandora take off? He's like, well, you know, our like algorithm and everything for matching songs was pretty good, but I hadn't in with Apple and they had known what we were working on and we need, and they needed apps for when they ever, when they wanted to announce it on stage. And we were just, we spun up an app relatively quickly. And because of that, we had the first mover advantage and he created a significant amount of wealth that way. You know, Pandora, you know, it was, is, is still pretty big. And when I look back at like these Jeff Bezos interviews on 60 minutes, when Amazon is like four years old and I like, I'm always envious. I'm like, well, we know it worked now. And I just so wish that I was like 30 years old back then, where I could have just like jumped in and had a very high chance of building something, uh, historical or something like even mildly successful. Do you think that that moment is happening right now where this is the space and it's happening this second. And even if you have just a mediocre success, it could still be a huge win because you're catching this tidal wave. Do you believe that this is the same thing now? Yes. I look at, you know, once again, I've been in software for 30 years now doing startups pretty much my entire professional career. The only time I've, I've felt like, like how heart palpitations kind of like Sean kind of opened with us, like there's this party going on next door and I'm here knitting, right. It's like, this is like too big to ignore. I think it's the single largest opportunity and biggest kind of tech paradigm shift we've seen, uh, since the internet originally came out. Like mobile was big, um, but there was a discrete set of use cases. Like when you put a camera on a phone, when you put a GPS on a phone,\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"device on a phone, a bunch of consumer apps like Uber and others came up and that was awesome, right? But it was not like this impacts everything like the internet did. It's like, okay, there's some businesses, some new opportunities, lots of good things, lots of money made, lots of startups. Awesome. This is an order of magnitude bigger than that. This is like the original web because it just opens up for all sorts of industries, all sorts of businesses, startups and incumbents alike, just lots of new opportunity. So this was not my original plan, but we're going to geek out for a little bit. We're going to do the geekiest thing that's ever been done on MFM. And the reason I'm going to do it is, so you brought up Pandora and he is a super bright, brilliant guy. And he had the matching algorithm, which was the differentiator. Yes, he had access and he got lucky in terms of the access, but the algorithm, if that had not existed, had the thing not actually been cool, it would not have worked out like it did. Now we have an opportunity. So I'm going to tell you, we're going to talk about, I'll give myself two minutes and we can cut this out. This is the beauty of editing. And we're going to talk about vector embeddings and why that's going to change your world. And before I can talk about vector embeddings, I'm going to explain to you how they work. Cause I had to go through this with my 12 year old because he was curious. All right. So we're going to do a super geeky thing. Now I want you to imagine a line, like you're a geometry class and you can put a point on that line that says, Oh, that's like three units from the origin, right? It's like, Oh yeah, point A is three units from the origin and point B let's say seven units from the origin. So one thing we know for sure is that we can calculate the distance between those two points, right? In that particular case, it's four. If you move to two dimensions, now you have two numbers that describe every point. So you can say, Oh, point A is here at these dimensions. Point B is over here with those dimensions. And we can physically, you could probably measure with a ruler, but there are mathematical calculations based on those numbers to calculate the distance. That's intuitive, right? You don't need to know fancy geometry. It's like, Oh, there's a finite distance in two dimensional space where we can calculate the distance. Okay. Awesome. Three dimensional space, exact same thing. Just three numbers describe every possible physical point in three dimensional space. Now here's where it starts to get a little more interesting. That just happens to be our experience. So we limit ourselves to three dimensions. Imagine in an abstract world, there are a thousand different dimensions. Okay. So abstractly, that means there's a thousand numbers that describe any particular point in this 1000 dimension space. Okay. Now foul that thought away that says we can have an arbitrary number of dimensions in this abstract world. Okay, great. Now imagine every paragraph, blog posts, anything you write, you can reduce down to a point in this 1000 dimension space. It's like, I'm going to capture the meaning of Sam's last blog post or Sean's last tweet. And I'm going to reduce it down to what's called a vector, which is basically a set of, let's say, a thousand different numbers that says this thing, if you plotted it, that point falls right here. And then you can plot something else. It's like, Oh, that falls over here. And just like in one dimensional, two dimensional, three dimensional space, you can calculate the distance between those things. And this is not keyword matching. This is what's known as semantic distance. What, how related is Sean's tweet to Sam's blog post meaning wise. Okay. So now if you take that, it's like, okay, well, if you, that means you can take any concept and reduce it down to a vector. That means you can measure the distance between vectors and you can find out how related two things are, even though they use completely different words. That's vector embedding. And the reason I'm telling you this is one of the biggest opportunities in AI right now is to do what Pandora did. It's okay. Is there an industry where right now we're doing really stupid keyword based matching somehow it's very, very crude. If I can take that same data set and convert it to vector embeddings and allow people to find things in a different way than they've ever been able to do before. So it's like Google search, super, super smart, not just keyword based, but for everything else. What's a real life example of this. So I'm going to take it to you, Sam. So you have Hampton now you're going to build up these profiles, very, very rich profiles of rich in terms of density, information density of members that are part of your community. Now imagine as part of that process, you're going to have some data and they're going to opt in and they're going to say, oh, here's the story of how I started my business. Here's the story of my biggest struggle right now. And sometimes people are going to say, oh, my struggle is growth. Sometimes they're going to say, oh, my struggle is it's really hard being an entrepreneur. And it has a really negative impact on my relationship and my family. Right. And they can talk about lots of different things. That's not going to show up in a profile. No. Now imagine if you took that content that they opted in and created vector embeddings of every member that you have. And then you can say, you know what, I want to find someone not that's in my industry or a company my size or happens to be my geography. I want to find someone that's dealing with these kind of founder therapy level issues. Who are those people? Let's find the semantic distance between those vector embeddings across the thousand, ten thousand, hundred thousand people that are in Hampton someday. That's a billion dollar idea. And that billion dollar idea occurs a billion times across the entire industry. Sam's going to go to the office for Hampton and be like, guys, Victor's embedding. Well, who's Victor and what's he embedding? We're doing it. I don't know what it is, but we're doing it. That's really that's really interesting. So you could do that with dating. You could do that with a bunch of different any different topics. You could do with unstructured data. But the idea is you're converting meaning, um, English text meaning or whatever language text meaning into something that's mathematically calculable as a result of which you can distance as a simple one, but you could do proximity. Like find me the top ten people that are in a radius of X from where I am right now. And the minimum has to be this in order for it to be close enough of a match to for it to be considered. There's a bunch of like new, like, two people, six. And by the way, the technology today that near mortals in a weekend can actually build a vector embedding model of a given data set. It's not that hard. I mean, it's not like rocket science yard. This has existed, though. And so what makes this better, you think? And also, that assumes that the people telling you information, it's actually they're saying what they mean. Right. Which is like, for example, I remember reading about OkCupid and people would say, like, one particular thing they had was about was about race and height. And they would like people would say they are open to dating these types of races, but their actions were different. There's a whole book called I forget what it was, but you guys will probably know I'm talking about where people say one thing, but their Google search history says something totally different. So does you're making the do you can this technology work even if people aren't telling you entirely accurate things? It depends on what your definition of work is. Right. So in that example, I would bet you money with a large enough sample size, the inauthentic posts would be uncovered by the AI like relatively quickly. Like the pattern matching would say, you know, this actually doesn't occur in real life all that often. And every other time we've seen this, we've had people that ended up being and you just have to have some sort of what feels like an eval functions. Like how do you measure the success of what the algorithm is doing in Pandora's case? Like, OK, do you actually like the songs it's recommending to you? That's the kind of arbitrary truth in a dating app. It's like, OK, well, are people liking the matches that are being made or if they felt that they were misled, that shows up. There's got to be some feedback loop. There's got to be a way to train the system that says, here's what good looked like and here's what not good looks like. Sam, you said something like, oh, they have to tell you the meaning. No, they don't actually have to tell you the meaning. Right. Because the I can interpret the meaning, summarize the meaning. It can it can guess the meaning based on whatever the raw the raw text is, the public text is. So you could just tell a story about your life and the I would infer or or place a tag, some meanings to the story that you told that, oh, this is about overcoming hardship or this is about whatever. So I don't think you actually have to get the participant to to give you the meaning. But let me ask you, Darmesh, like in Pandora's case, I don't know how Pandora works, but let me just guess for a second. Like it probably takes the tempo of a song and it's like, oh, this is a fast tempo song. It probably takes, you know, maybe the key that it's in or something like that, that that gives you like, is this an upbeat and fast and joyful thing or a sorrowful, you know, mood song? So it gets like mood, tempo, artist, and like whatever, a couple of key characteristics. There's like there's instruments in terms of what what's actually in the thing. And yes, so he had. By the way, when they first started, they did it all by hand. So we had like 500 ex-musicians listening to it and like writing down, like checking boxes to what it was. It was pretty wild. This data is wrong every freaking time. Have you heard of HubSpot? HubSpot is a CRM platform where everything is fully integrated. Well, I can see the client's whole history, call support tickets, emails. And here's a test from three days ago I totally missed. HubSpot, grow better. So let's say they did it, they use attributes. And if I want, let's say I wanted to do this in fashion, I say, oh, man, I love Sam's jacket. I want to find, you know, similar jackets. Can you match this to me? One way would do it. OK, Sam's jacket, let's say it's blue. It has buttons. It has blah, blah, blah. Right. It would take attributes. And are attributes the same thing as meaning in this case? Or is this more for things that are like text based and content, you know, like content that has some meaning? Or does this work for everything? It can work for everything. And we're still kind of uncovering because this stuff is kind of moving so fast. So what you're talking about is what we've been using in e-commerce forever in a day, which is a faceted search that I have a number of dimensions or factors, size, color, what type of clothing is it, all those things. And then you kind of do this faceted search. And then we've had kind of pure text based, the keyword semantic search. This sort of sits in between. So instead of having to tell it, here are all the facets that I'm interested in, it kind of pulls those things out that are relevant.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"based on that large language model. And this is, so the idea of vector embeddings and semantic search has been around for a long time. That's not new. What's new is these new generative models now that are much, much better at understanding all of like documented public human knowledge and then using that to say, oh, like when you use this word, when you use coach in the context of a relationship, you're probably talking about like a therapist, it's just a different word, right? Like that's sort of what you're talking about. And Sam, you talked about this, I think in the last pod is in, anyway, so it's more about the meaning and it infers or figures out what the dimensionality is. And that's how it kind of translates into those vectors. There's a couple of these companies. I just saw one Pinecone. That's like some vector, these things are getting valued. By the way, that's. What's that? Pinecone is the number one vector database. So let's say you had to take these vectors and put them in somewhere, which you do, in order to be able to do searches. Pinecone is the number one most popular commercial. And I think they just raised it like a $700 million valuation or something. And there's like three of these that just raised these mega rounds. Because, and that's, you know, I don't even, I didn't even know this. It's so funny, you just came on here being like, let's talk about this super niche, nerdy thing. Just yesterday, I was like, to do, go figure out what a vector database is and why these companies are raising so much money. Like this is clearly a big deal. And I don't know what this, I don't know exactly what this means, but now it makes a lot more sense. So it comes full circle, Sean. So you know what, maybe it wasn't as geeky as I, I just like, it's actually useful, right? You've done an awesome job explaining like the theory. And I'm like literally sitting on the edge of my seat, thinking like, this is crazy. And you answered that question where I said, is this like the new internet, opportunity-wise? And you're like, yes, absolutely. But when you're making the stuff, what are some of the tools that you're using to, you know, to actually, you said this isn't rocket science and someone could figure this out in a weekend. What are you, what tools are you using to do all this? Yeah, I mean, so language-wise, the most common is Python. That seems to have emerged as like lingua franca of the AI world. Not to say you can't write it in TypeScript or pick your language of choice. And then tools that are emerging, it's still early, right? The Pineco we talked about, there's another one called, an open source project called LangChain. And I met a member of LangChain, Harrison, at the Sequoia event, super nice guy. I asked somebody yesterday, I was like, how do I, you know, is this a company? Can we invest? Because everywhere I look in these like AI hackathons, it's all about LangChain. And it's like, no, it's not really even a company. It's just an open source project. There's a guy who made it, but, and is running it, but it's not even a company, correct? It's not a company yet, but you know. Wait, is it, is it Blaine? What that? Blaine? Chain? Lang, as in language chain. Oh, okay. LangChain. And what it does basically is it lets you chain together. So right now, when we work with large language models, we kind of send in a prompt, what's called a prompt, and you get something back. And then you maybe send it to another thing to do something else. And there's like a multi-step process. Amongst other things, LangChain helps you kind of chain those things together, and makes it easier for you to kind of work with either an individual large language model, like GPT-4, or get class models, and then kind of do a lot of the kind of connecting of the dots and help you with that. But it's a super useful library. We missed the chance to give an example, more tangible example. So you talked about the plugins thing. I think, you know, example use case here, tell me if I'm wrong, because I haven't, nobody has, well, very few people have access to the plugins thing. So I'm just kind of sort of guessing, but like, if you go to chat GPT today, you say, hey, I'm gonna go visit Austin in April. You know, make me like, I'm there for four days. I'm with my family. Make me a travel itinerary that is gonna be fun, family-friendly, we wanna eat good food, and maybe do a little bit of sightseeing, but not too much. It will spit out a day-by-day itinerary for you. Okay, that's kind of interesting. Now let's say, oh, I need to, I'm trying to figure out where to stay. What hotel should I stay at? You know, here's some things that are important to me. And it will give you a table that's like, here's option one, option two, option three. Here's the cost, here's the whatever, right? And it can do something like that. And with the ability for plugins, you can now say, cool, can you just book that for me? And it will just be like, great, we have the Expedia plugin or we have the Airbnb plugin, and it will just go ahead and book it for you. And so, you know, do you need an executive assistant? Do you need a travel agent when you could do these things? Do you need, you know, the same thing with HubSpot or Salesforce? Oh, you know, give me a list of this. And it gives you a list of that. Cool, put that in an air table for me and or put that into Salesforce and tag the highest value opportunities as blank. It'll just go and do that for you. And it'll give you the link to your Salesforce dashboard. It's like, whoa, that's kind of cool. Like, that's a task that some, you know, I would normally have a human go do because now OpenAI or ChatGPT is not just going to chat you an answer. It can do things as long as the programs that let you, you know, they'll build the interface so that ChatGPT can actually interact with those things. Yeah, and this is actually a great example. So I think, and we can use that to kind of open up kind of doors for the viewership and listenership, which is okay. So travel, which is something we all kind of intrinsically know how it understands. Some of us might remember the evolution away from travel agents. And the first thing we did when we kind of had web-based kind of travel bookings is we treated very transactionally. Is I'm looking for a flight from X to Y sorted by descending pain, sorted by price, whatever happens to be the fewest stops, lowest time, whatever it is. And they do a pretty good job of that. Like most of us have used one of those. What's going to be possible now in this kind of new AI world is instead of solving for the transaction, you solve for the experience. And what I mean by that is that, oh, if you had an all-knowing assistant that was super smart and scored, you got a perfect score on their SAT and was going to go out there and do something, okay, what you're really looking for is to solve for this experience. You're going to want to stop by this thing and you're going to want to find a hotel that's around a Michelin rated restaurant because you only have 15 minutes to get between this point and that point. And I'm going to pull the whole thing together for you. Oh, and by the way, your wife's going with you on this trip. I know she likes that right now. So normally I would have put you over here, but this time I'm going to put you over there. Oh, and by the way, I know a week ago you were at this other thing and you had mentioned that you would actually like to follow up with some of those people. I'm going to see if I can make that happen as a, like all of that, right? Imagine it knows everything about you, has access to the transactional engines to book the flight, has access to all the information to get ratings and reviews, and all of that comes together in one chat-based interface. Fucking insane. This is crazy. Are you, is this why you bought, so you bought chat.com, right? I did as of, transfer the domain yesterday, last night. And you paid, you just said eight figures, so 10 plus million. Yes. Unless you're including the.00 as a figure. Is this personally or you're doing this in HubSpot? Is this a HubSpot domain? Portfolio. So put this, so if you go to chat.com, it will take you to a LinkedIn post that tells me, it tells you why I did it and some of the details. So I bought it personally. Wow. And the reason is because of this conversation we're having right now, which is I think chat as a experience, as an interface is the future, right? It's like, that's the thing. And no one tends currently to kind of build something out on it, but it's, the domain, I think it was like dormant for like 30 years or something like that. And there was, kind of came on the market. And yeah. Wow. And, but you, so, so this is insane. I'm reading your post now. It's pretty wild. Do you have, are you using HubSpot employees? Like, do you have like a Skunksworks team inside of HubSpot that's just working on all this wild stuff? Or do you have like a side LLC or something where you've got like a handful of people on staff and you just say like, here's what I'm interested in this week. Let's see what we can come up with. So the way it's working now is that there will be times where I'll do something as a hot, like WorkPlay is a good example where I'll build something on the side just for fun, for learning, whatever it is. I put the bill for, for no HubSpot PNLs are harmed. And then there are times where like something kind of winds up being, so I started this project called ChatSpot because I'm obsessed. And we'll take a walk down memory lane because I think it's instructive. So I built this application called Chatspot.ai. And the idea here was- You built it or a team? Mostly me. I don't have any front end design skills. I've got some freelancers on it. So, yeah. Yeah, so I used OpenAI's APIs to build it, but my kind of target goal, the thing I had in my head is I built it for myself. Like here are things I need to do all the time and I'm pissed off that I have to do them manually every time. And this has been the story of my life for 30 years, right? Like solve my old problems and then other people may or may not find those things interesting or useful. And so I built it, but okay, here are the things I wanted to do. Like access HubSpot, I want to be able to look at my outlets from yesterday or ask questions or look up a domain name or I wanted to see the history of a domain name. I like all these things. It's like, okay, well, I don't want to like, and I have all this software, a lot of it just built. And I just run it from the command line, I do things. And so I then I'm like, okay, I can wrap this up into a chat-based interface. And so I've been doing that, working on it. We've made, and so now given the relevance to HubSpot, we're going to transfer that project, chatspot.ai to be a HubSpot staffed core team. This is going to change the world. It's going to change the world of CRM. Let's go do this, which is great. So, and my working thing is like this. What are you doing with chat.com? What's the plan? You bought this amazing domain. You redirected it to your LinkedIn post, which basically just tells the world basically just tells about the purchase, but what are you actually going to do on the domain? I don't know yet. That's the honest answer. I do not know yet. Amazing. And okay, so we can help you brainstorm. Yeah, we can definitely do that. By the way, the chatspot.ai, did you go to that, Sean? It's a simple looking website. It's one page. And there's a 19 minute video of Dharmesh sitting in the exact same chair. Doing the big talk. It is way big. Hey, it's me. And it looks almost like, but he's really good at these videos. It's almost like he's reading a script, but you come off natural. I don't know if it's a script.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"or not, but it has 200,000 views. And it's a 19 minute video of him talking about what this product is. And you do the best combination of like launching something really quickly and getting it out there. It's just you on in your chair talking. And yet, it's like a pretty sophisticated thing. And it has 200,000 views on this video over just about that's wild to me. You like it's I got it. I gotta give you credit. You, you are kind of amazing. Like, you know, you said a bunch of things in this podcast, and I don't know how many of them I'm going to remember maybe the vector thing because I enjoyed that math lesson. But the main thing is I go around my life now. And I just looking for people who I'm like, I want to be like you when I grow up, and I'm just taking little things from them. And they could be it could be like a, you know, 17 year old kid who's just like, doing something awesome on Tick Tock. And I'm like, I want to be like you when I grew up, that guy who made that Kanye vocal, like transformer, I was like, I want to be like you when I grew up, I'm just taking little pieces. And you have a couple of things that I think are kind of amazing. You have a combination of enthusiasm, like you come on to this podcast, and you are pumped. So you are as excited in year 30, or maybe more in year 30 of your entrepreneurship career as you were in year one. And I'm like, Oh, this, this is great. That's the fountain of youth is that enthusiasm. So like, he's got the enthusiasm, then I feel like no matter what's happened, no matter how much success you've had, you've kept your schedule and your use, you invest your time into things you like. So like you tinkering on this project, whether it's wordplay, last time you came on, you told us about that. It's like, wordle is awesome. But I got annoyed with these things. So I made a me and my son built this project together and like, you know, to teach him but also to just make the thing we want. And like, look at this, it kind of works. Even if it didn't work, it would have still been worth it. So like, having that kind of like, I'm always going to tinker because that's what I love to do. It doesn't matter that I'm the you know, top dog at this, you know, multi billion dollar public company. That doesn't mean I'm going to stop doing the thing I like to do. So I love that love that aspect of it. Third, you are really great at content, you do this like dorky form of content that's just like, Hey, it's me, I'm going to show you this thing that I'm pumped about. And like, you don't overthink it, and you just do it. Whereas like, I think most people get really gun shy when it comes to content. They're afraid about like, you know, how to do it, what it looks like, you're just like, Oh, no, I'm just gonna like, I'm gonna say the thing that I'm excited about, I'm gonna say it. And I'm gonna do a screen share. It'll just be me and my screen. I'll be talking about what I'm doing. And I love that. And so and then last one is guts. So I feel like you put your money into things you believe in whether it's philanthropy, or in this case, buying a $10 million plus domain name with no plan. Like you just said, it's like, you did the the fire ready aim. Like, yeah, I bought the thing. And now I get to figure out what the hell I'm gonna do with it. I think that takes a lot of guts. And I don't think you see things as risky as other people see them. And it's not really about like, I think the easy way of saying it would be, Oh, yeah, well, it's, you know, that's nothing to him. He's got a lot of money. Yeah, I don't think that's true. And I know a lot of people with a lot of money, and they don't do things like this, where they just put their money behind things that they're in, they believe in, or they're interested in, or almost like, would you I don't know if you would agree with this. It's almost like you ended up so that now you're forced almost to do something awesome and interesting in this space that you think has a lot of potential. But then there's this in this last thing is this rare combination of like, and I mean, this in a polite way of which I am also that like this nerdy nerdiness, quirkiness of like, I'm just doing it because it's cool. Plus, I'm this way can make money. I mean, you have a way that makes. Yeah, you have this company that has close to 2 million and 2 billion in revenue, and is a commercial success and then artistry of like, I'm just just like, this is beautiful. This is awesome. I'm gonna do this. It's a very rare combination. How do you respond to all these compliments? I'll say this, the lesson kind of I've learned over the years, and I think this is if I had to kind of share any kind of advice over the 30 years is that when I've done best is when I've had the courage of my convictions of something that I believe in. So I'm going to tell you like a quick story of the road that led to me buying a 10 plus million dollar domain name. I almost like said the number actual number out loud. I have to kind of catch myself. But and so 17 years ago, I had and I this is before HubSpot. I had this idea. And the idea was everyone was using kind of email and Outlook back then. This is before the iPhone before all the things. It's like, you know what, like business software is really hard to talk to. I'm going to do it just like I would email my assistant. I didn't have an assistant, but let's assume I did. You know, I just want to be able to do that and type of email up and have her like, Oh, I have this file in our shared file server in SharePoint somewhere. Can you just send me a link to that file about to hop on a plane? I need that for the sales call. I'm going to go on for for a meeting tomorrow or I'm on the plane coming back. I just ran this person, whatever. I've got their business card right here. This is before the iPhone and you can do OCR and things like that. It's like I'm just going to type that in and send it. I just add this to to my contact database or whatever. And the beauty of email was it already had a disconnected model. We already figured that out, which is, oh, you can be on a plane, have no internet, type all emails you want, respond to all the emails you want. And then when you get connection, it does all the things right. This is like automatic synchronized database, essentially. And I called the product Ingenimail. And that's what I was going to do before HubSupply. I was like, Oh, that would be an interesting thing. And then five years ago, I'm like, OK, well, that Ingenimail thing, the core of it was a good idea, but email is the wrong conduit. It actually needs to be like a web based tool or Slack, which I did both. So I built this product called Growth Bot. Talked about it on the inbound stage, got thousands of users, threw it out there. And it was awesome, except for one thing. It didn't work. It like it couldn't actually do the natural language understanding that I wanted it to do. Despite my best, I used products from Google called Dialogflow. I used products from Facebook. We used open source projects to try and crack the nut of taking text, understanding what the hell the user was trying to do anyway. So that failed. And then, you know, when GPT comes along, I'm like, Oh, you know, that thing I've been thinking about for 17 years, that actually is now possible. So I start working on chatspot.ai. I'm like, OK, it took 17 years, but I sort of proved myself right. I had the courage of my convictions all the way through to never let go of that one idea. And then chat.com comes along. It's like, OK, it's like deep down inside, I will give you the true, honest to goodness reason I bought it. The reason I bought it, and this is, I think, a phrase, Sean, you just use this like, Oh, no, I think Sean, Sam, you just use it. It's the anti. So I'm trying to get into the AI party. All the AI parties. And I'm nobody in that particular party, right? I've done some things in some places, fine. But that particular group of people has no idea who I am. Not really. So chatspot moves me in that direction. It's like, Oh, some people have seen that video. Awesome. Chat.com for let's say I even break even, let's say I lose a few million dollars. It is worth the price of admission for me just because that pays the cover charge. I was like, OK, this guy gets it for him to spend that kind of money on chat UX, which Bill Gates just talked about last week as the new thing. So you should read that article. Gates just did an article around why he is so excited about this generative AI stuff. He tells the entire story of how he came across on Altman and OpenAI and the challenge he put to Bill Gates. And his, I'm going to paraphrase, he said when we went from DOS to Windows, which is we went from a character based interface to a graphical mouse based click and touch interface. That's the thing we built Microsoft on, which lasted for decades. And they said since then, there has been nothing in technology that has come along. Literally, he said nothing that has come along that has made as or will make as big of an impact as this natural language interface to software. It's the biggest thing we've seen. And hence, chat.com. What happened with that, I don't know, but the wrong with scary is have the courage of your convictions if you truly, truly believe in an idea and you fundamentally think you're right. Iterate. Don't just go down your rabbit hole. Tell everybody you can about it. Build products around it. Find other like minded folks and try to pull on that thread. But would you ever quit HubSpot and just spend all your time on this stuff? I don't really need to, right? It's I enjoy what I do at HubSpot. I think I add value there on that a dollar salary. So it's not the not the money at all. Like even on the like the chat spot thing at the time that I built it, it was experimental. I'm like, OK, I'm not sure if this actually accrues into something that would be valuable to HubSpot. So spent like half a million dollars plus on like freelance developers and open AI license fees and all the things that need to go into launching a product like that. And I'll end up giving it to HubSpot for a dollar. Right. I'm not looking. Yeah, but aren't you? Aren't you like I don't want to be weighed down by this baggage of like having to worry about CRM stuff or, you know, your technical you're the title your title CTO. Like I don't want to have to talk to certain people and take up meetings on like the future of this particular product. Instead, I just wanted to just nerd out on all this other stuff. But I do that now. So I've got one thing. One of the things I've this is a personality called a trait slash flaw is that I spend most of my life trying to configure the universe to my liking. That's all I really do this. Right. That's one of the reasons they kind of go into startup land is the freedom and the control to do the things you want to do. And so I've kind of crafted a role for myself within HubSpot that allows me to do exactly the things I want to do and not do any of the things I don't want to do, which is one on one meetings that I have to manage.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"people have no direct workforce. Don't I've never filled out an expense sheet. I like I do none of that. I feel I feel I don't know about you, Sean. I feel like I feel like I want to quit everything I'm doing. Like he's just persuaded me. I just watched yesterday. No, it's over. I feel it's over. So here's my advice to you, fam. It's um, do I mean, do you feel this way? Sean? I don't know. Sorry, Dharmesh. Go ahead. No, so my advice to you is Hampton's a cool idea with actual utility. And Sean, you said this in the last thing like this could be a hundred million dollar business worth anywhere from 300 million dollars to a billion plus dollars. And I think you're right. If you're excited about some of the new technology developments that's happening, I think the best thing you can do is intersect the two things. It's like, OK, I'm going to build Hampton and take the things that I know. I know how to build communities. I know how to build these kinds of businesses. Now, can I intersect that with things that are happening in the technology sector around AI or whatever it happens to be? And then it can somehow merge those two things, because then you'd be an unstoppable force. Right? Because no one in the community building market doing niche market communities is thinking about or having conversations about vector embeddings. I promise you that. So you don't have to give up one for the other. You can say, yep, I'm going to do that. I'm going to do it better than anyone else has ever done it. But I have a different advice for you, Sam. I think just get dug in into your position instead. I remember when you were doing the hustle originally and Snapchat came out and Instagram was like popping off on videos and Facebook had videos. And then there was other media companies that were raising tons of money that were just like, we're going to produce short form video content or live video content on top of Facebook. And Cheddar was all the rage and all the stuff. And I was like, dude, why aren't you doing videos, man? Look at this. Look at these guys. Look at these guys are getting millions of views on their videos on Facebook, or these guys are getting millions of views in the Snapchat story feed. You could be the first one there. It fits your audience. And you were like, just very steadfast. You were like, your principles. You were like three things. Number one, don't understand it a lot. I don't really understand it. I understand this other thing, too. I could try to figure it out, but I don't want to build on top of their platforms because they change the rules all the time. I have friends who got burned by that. I don't want to get burned by that same thing. I don't want to build on a shaky foundation. I'd rather do email because I own the thing. I own the relationship with the audience. And it's not like the Facebook algorithm changes one tweak away from putting me out of business. And I remember being like, man, this guy's like Mr. Stone Age. Like, he is just not integrating or adapting to the new shit. I was like, I would. There's no way if I was running the hustle, I would have been able to resist the shiny object of video on mobile phones. And it turns out video mobile phones did turn out to be a big thing. But a lot of those media companies got absolutely wrecked. And you were right for being wary of it. And I don't think in this case, people are going to get wrecked because it's not like the analogy is not one to one. But I would say Warren Buffett missed the internet and all of technology and still did fantastic. Sam, I think you're going to be in that same boat where it is not really in your nature to get really interested in new frontier technologies and play with them and try to integrate them. And that's not really your nature. And you're best served by knowing your nature and just doubling down on what's a working formula for you, I guess. So I would do that. I appreciate that. Because there's going to be a trillion people trying to do fancy AI shit who are better suited to do that. And it's going to be an absolute bloodbath for like, go look right now at the number of AI tools that are coming out every single day. And you know, it's like most of them do seem shit, though. You're right. I mean, like, it doesn't matter. It's just swarms. And they're all going to get just like wiped out. Every GPT release wipes out a whole wave of like, even the successful ones, because it's like, oh, now that's just a feature of chat GPT. And so I don't know, I think it's like know your nature. And like, you know, it's okay to not have to do every new thing. Unless that's your nature, unless like, like for Darbash, it is his nature. For me, it is a lot more my nature than it is yours. And there's pros and cons that come with that. And so I think are you, are you going to go in? I mean, Sean, Sean's got a new idea that he's sticking with. And he's been telling me a little bit about it. I have one piece of tactical advice I have to share with you, Sam on. So I was going through the application process on Hampton last night, like 2am. And this is super tactical, but this is what we do here on MFM. Question number nine on the application process is what's your role? Question mark. It's a required question. Good. The subtext is CEOs, founders and partners only, please. That's the subtext. The options are founder, CEO, owner and other. The one thing I would tweet if I were you. So what you're doing is you're saying, hey, we're about founders and owners. And if you're not one of them, don't bother. Don't bother. Thank you for not bothering. Go away. So focus is a magical thing. I love that. But you're doing what I call a pre-filter, right? Which is why not say, oh, this is for CEOs, owners or whatever. Don't make them feel guilty for going through the rest of the process, because there may be a future version of Sam and Hampton that says, oh, you know what? We solved this problem. But that same problem around people needing therapy from peer groups applies a lot to like VPs of product and that community right now. All the only communities they can find are people that want to talk about product management and no one wants to talk about relationships. And there's an opportunity there. And so it costs you literally nothing. They'll still answer the question. It'll be sitting in your database for a year or forever, and it costs you nothing. Don't push them out too early. It should have been the way you suggested. Apparently, I didn't give that feedback. Grant, if you're listening. This is a direct order from Darbass. Change to question nine, please. Grant, do this before you get replaced by AI. Yeah, but Sean, you're telling me. Thank you, Darbass. Sean, you were telling me about stuff that you're thinking about. Yeah, and it was pretty it was somewhat old school, like what you're the thing. Yeah. So are you like questioning that after this conversation? And you're like, oh, man, this is like not after this conversation, necessarily. But it's a snowball that's building right. Like there's a reason I clearly said that. I just mess around with AI all week because I'm interested in it. And when you it's like, let's go see what's real there. And I did the same thing with crypto during that during when crypto was really interesting. Intriguing. I was like, OK, let me go try to mint an NFT. Let me go try to actually use DeFi and see what's going on here and what parts make sense and what parts don't make sense. Oh, that was pretty frictionless. Like, that's cool that I could just get alone in one button and I could pay it back in one button. I never had to talk to a human being like I really like that. Hey, this thing says the yield is 20 percent. I don't really understand where they would get 20 percent from. So not sure. But I'm going to put a small amount of money in just to learn. I was I was trying to play with it, trying to think for myself is the big idea. And and it's not like some binary thing like is crypto good, is crypto bad. It's like I want to know where it's at right now. I want to see it develop. And my best way to do that is immersion. I actually stole this from the from Bill Gates. Bill Gates does his reading week where he goes to a cabin and he reads the book. It's his reading week where he goes to a cabin and he reads a shit ton of books for a week about one topic that it's like been on his mind, but he hasn't had the appropriate amount of time to roll up his sleeves and dig in. And I was like, oh, that but without books, just give me a Chrome browser and I'm good to go. And so so that's what we've been doing. And there genuinely are so many like mind blowing moments and also just like just understanding the nuances of things. So for like just being able to think like the computer, like, you know, you were talking about these facets, for example. So I was playing around with mid journey like Sam, you know what mid journey is or do you know how to use it? Yeah, yeah, yeah, yeah, yeah, yeah. I mean, I just been goofing off and I'll just be like, show me what's Cartman from South Park looks like as a real person. Right. And like, you know, I was like, can I was the way I approach it was can I replace work that I already want to do with a more efficient AI workflow? That was like one of the things. And then it was what's really fun, random shit I could do. I wanted to be on those ends of the spectrum, like highly utilitarian for me. So it's like, oh, I need a logo for my thing. But I don't want just like a logo. I want to create a whole brand. All right. How can I use AI to create a whole brand here? So from the icons to T-shirt designs to a website, can I do that with just AI and not have to touch it does not have to hire a single designer? And can I do that with just like my own imagination and this prompt thing? And then, oh, how do you do prompting? And like, which of these tools is the best? And what's the difference? So that was like one whole area. Another was like we took the podcast and we did this thing that was kind of sick. We took the podcast and we ran it through this thing. So we took the pod and we then used OpenAI has this thing called Whisper, which transcribes any video. So it's like put in a YouTube link to this tool. It'll take Whisper and it'll give you the transcript. All right, cool. It takes the transcript. Then I put it into chat GPT and we had this guy write this little prompt for us. Like we had to get the right prompt, but he wrote this prompt that was awesome, which was basically like it's pretty funny. It goes because chat GPT can only take so many characters. So it goes, I'm going to give you 19 text sections. I don't want you to do anything until you're at section 19. So ignore everything until I'm done with 19 and then answer the prompt that I give you. And chat GPT is like, okay, I will wait for the 19 parts. You copy paste part one, two, three, four, all the way to 19. And then you go, the prompt is I want you to pull out every idea, story and framework that's discussed in the podcast. I want you to summarize it. And I want you to tell me, does this idea exist already or not exist? It can guess based on the way we were talking about it. Are we talking about something we saw that exists or not?\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"or just an idea that somebody should go do. So like from this pod, it would be like using vector, using this vector, you know, dimensions or I forgot what you called it, vector engine or whatever to potentially create a dating site that would match people in ways that they're, you know, sort of similar using AI. And it would be like, does this idea exist? No. Who is the source of this, Dharmesh? What was the synopsis of the idea blank? What is the category that it's in, AI? And so then it took that and it takes the whole episode and it just created a database of every story, framework and idea from the thing with these tags. And now a human can go back and like tweak them if something was wrong, but like that's a lot of the work that was done. And we could just do this for the whole back catalog of our podcast. And so I'm trying to use it first for my own benefit. And then along the way, if I see a business, a startup idea that I'm like, oh, somebody should productize this or somebody should do whatever. Like, you know, the simple example is this Kanye thing. I was like, why is this not the most viral app in the world right now? That basically it's an app with a one button that says, you know, say something. And then it's gonna, when you let go of that button, it's gonna turn it into Kanye saying that thing and go share that to TikTok. And like, you might get sued, but you will go viral. Right? That's the trade there. Like that's crazy. There's no front end for this really cool, you know, AI demo that exists now. So yeah, I'm just right now I'm in the go play around with it, see if anything really, really strikes me. And if something does, then take the next steps. There's one thread in there, Sean, that I think we should pull on, which is you used, you talked about this kind of crafting of the prompt in order to kind of make the thing do what you needed to do. And that's entirely new skill now called prompt engineering, right? And it's analogous to software engineering. So software engineering is getting a computer to do what you want by speaking to it in its language. And that way you can kind of get the results you're looking for. Prompt engineering is almost exactly the same thing, except you're talking to a large language model, something like a GPT-4 to kind of get it to produce. So you're talking to AI to get it to produce the thing that you want. And so I think this is another opportunity for folks that are kind of technology minded, but not like software engineers, right? So they kind of can think about the problems in their head. They're good at it. And they may be good writers. They may be good analysts. They may be good at kind of describing the thing, but like prompt engineering is gonna be like another big, like a big thing. And by the way, as long as we're dropping things, so I bought two domains recently. I bought one of them. I bought one of them. What's that? Buy one, get one free? Yeah, I wish. But this one got, it's not eight figures, it's seven figures. And the domain is prompt.com. And this one, I actually have an idea around what to kind of what to do with that, which is there's going to be this entire, I'm not gonna get into details of it yet because it's too good of an idea to actually just put out there in the world. And I'm not ready yet to do something about it. But once I get something- But wait, prompt? Prompt.com goes to like a coaching for essays. I know, but the transfer is still happening. I don't have the domain in my possession yet, but the deal is done. Dude, so your portfolio of domains, I mean, mid eight figures then. Tens of millions. Fucking insane. Dude, I feel amped. I like, when we were talking to Pomp, I like wanted to go like hide under the covers because he freaked me out about the billion or the million dollar Bitcoin thing and the banks. With this thing, I'm like, I got to clear my schedule. I got to go learn all about this. I mean, I feel amped. This is awesome. Before we go, give us your two minute reaction to Balaji's warning slash bet that the US dollar will crash and Bitcoin will surge to $1 million. I'll say this, and I don't know him personally, but he's like quite literally one of the top five people I've ever encountered, like even on the internet, there's raw, what I call wattage, just raw horsepower. And he's like an AI unto himself, right? Like just the knowledge that he has. Having said that, I think I understand why he's taking the extreme positions because that's sometimes what you have to do to kind of shake the world out of its reverie. And it's like, okay, pay attention here. This is important. But if I were a betting person, I would not bet that the odds are what you think they are. Could happen, but nowhere near the probability that he's suggesting. I feel better now. My personal take. I feel better. I like your opinion better, therefore I think it's true. Yeah. Yeah. Okay, we should wrap on this because one of the things that happens anytime new technology comes along, we saw this a little bit in the kind of crypto web free world as well, is that entrepreneur-minded folks will see this kind of new thing and they will look for kind of the quick turnaround. I'm all for creating value quickly, but it has to be like creating value. Don't play the arbitrage. Oh, I'm gonna do this thing. This is like day trading back in the day or whatever. It's like, don't be a grifter, right? Like be something that's gonna reach. We're gonna build a shitty app and put web three at the end of it. Yeah, like just don't take advantage of people. There's enough real problems to solve where real money can be made. And yes, this technology can now be used in creative ways by lots of people and you should use those, but don't use it as an excuse just to kind of be like an AI tourist that comes through and makes a little bit of money or whatever and that was that. There's a bigger opportunity. I think you're shortchanging yourselves if that's what you end up doing. Well, thank you, Dharmesh. Thank you for coming. This is awesome, man. Yeah, well, thank you for coming on the pod. This is awesome. I feel pumped, man. I always like talking to you. I don't know if you know this, Sean. I Slack Dharmesh all the time. I'll just be like, I'm just trying to get him to like give me a little like crumbs of information because I just like- I need to get into the HubSpot Slack. It's awesome. I'll just like send something his way, just hopefully I can get something back. But it's fascinating and I feel lucky to be able to have you as a friend and a coworker. And this is awesome. And a podcast guest, this is so fascinating. And I agree with what Sean said about like, kind of like looking up to you and like looking at how people live their lives. You're definitely someone I admire. So I'm happy you came here. Thanks for having me on again. This is fun as always. Awesome. All right, thanks for coming on. That's it. That's the pod. \\u266a\\u266a\\u266a\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      " 1 out of 18 Compressions  :  The co-founder of HubSpot, Dharmesh Shah, believes that generative AI is the biggest tech paradigm shift since the internet. He compares it to mobile technology, which brought a discrete set of use cases, whereas generative AI has the potential to impact everything. The hosts of the podcast discuss OpenAI, with one host suggesting that it is likely to be one of the most valuable companies in the world in the next ten years, and Dharmesh Shah agreeing that it is in the top three. They also discuss the controversy around OpenAI's transformation from a non-profit research lab to a for-profit company. The hosts conclude by discussing the potential uses of generative AI, including its impact on content creation and its potential to revolutionize industries such as healthcare and finance.\n",
      "\n",
      "\n",
      "\n",
      " 2 out of 18 Compressions  :  The text describes the history of OpenAI, a company focused on developing artificial intelligence, and its transition from a non-profit to a for-profit subsidiary. The founder of Tesla, Elon Musk, initially provided funding for OpenAI but later withdrew it, leading the company to create a subsidiary to raise capital. The subsidiary is capped in terms of profits and was created to cover the funding shortfall. The author also shares their personal experience with AI tools and how they used them to create an intro rap for their podcast. They also discovered a way to turn their voice into a Kanye West rap using a Google collab folder and a Kanye voice model hosted on mega upload. The author notes that it only takes around 15 minutes to complete the process and suggests that they are unlikely to be sued for using Kanye's voice for a short clip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 3 out of 18 Compressions  :  The text discusses the potential of generative AI in the creation of chat-based user experiences for software. The author notes that while most discussions around generative AI focus on text-to-text or text-to-image use cases, there is a third use case that is often overlooked: the ability to go from text to code. The author explains that this could lead to the development of chat UX, where users can describe what they want in natural language, and the software generates the necessary code to achieve it. This declarative model differs from the imperative model, which requires step-by-step instructions. The author uses HubSpot's report building tool as an example of how this technology could be used to simplify complex tasks, allowing users to describe what they want in natural language, rather than having to know how to use the tool. The author concludes that the potential of generative AI in this area is exciting, and it could revolutionize the way we interact with software.\n",
      "\n",
      "\n",
      "\n",
      " 4 out of 18 Compressions  :  The author describes their experience using an AI language model to create a simple website and troubleshoot issues they encountered. They were able to generate code for the website and then learned how to host it online using Netlify. The AI model was able to understand their requests and help them navigate obstacles in the process. The author notes that the conversational nature of the AI model allows for iterative problem-solving and it can even ask questions to better understand the user's needs. The author is impressed by the AI's ability to problem-solve and feels like it understands them rather than just guessing the next word in a sentence.\n",
      "\n",
      "\n",
      "\n",
      " 5 out of 18 Compressions  :  The text is a transcript of a podcast interview with a tech industry veteran who discusses the capabilities and potential dangers of GPT-3 and similar AI technologies. The guest explains that while some may view GPT-3 as simply a more advanced auto-complete feature, it is actually a reasoning engine that uses a set of facts to logically answer questions. While the guest is optimistic about the potential of AI to amplify human abilities rather than replace them, they acknowledge the concerns of others who fear that AI could be misused or take on a life of its own. The guest notes that the danger lies not in the impact on jobs, which could be offset by the creation of new jobs, but in the ability of AI to carry out harmful actions if directed by the wrong people or left to its own devices. The guest cites the example of a red team tester who asked GPT-3 how to kill the most people with the least effort as evidence of the potential dangers of AI.\n",
      "\n",
      "\n",
      "\n",
      " 6 out of 18 Compressions  :  The text discusses the potential dangers of artificial intelligence and the increasing number of doomsday bunkers owned by wealthy individuals. The author argues that while there is a possibility for AI to become uncontrollable, the fear of it is not new and may not be directly linked to recent advancements in technology. The author also shares insights from attending the Sequoia AI event, where the focus was on practical discussions about the future of AI and its applications, including text-to-image and text-to-video generation. The author notes that the natural language interface is becoming more advanced, which could lead to more seamless interactions with AI. Overall, the text highlights the potential for AI to revolutionize various industries but also acknowledges the need for caution and responsible development.\n",
      "\n",
      "\n",
      "\n",
      " 7 out of 18 Compressions  :  The article discusses the recent announcement by OpenAI to add plugins to its popular chatbot, GPT, which has over 100 million users in just two months. The addition of plugins will allow third-party developers to inject proprietary data sources and other functionalities into the chatbot experience, making it more of an ecosystem than just a chat app. The author compares this move to the app store for the iPhone, which broadened the appeal of the device. The article also mentions the potential for this development to create significant wealth for early movers and compares it to the success of Pandora, which had a first-mover advantage in its industry. The author believes that this is the biggest tech paradigm shift since the internet and that it will open up new opportunities for various industries and businesses. The article also briefly discusses vector embeddings and their potential to change the world.\n",
      "\n",
      "\n",
      "\n",
      " 8 out of 18 Compressions  :  The text explains the concept of vector embeddings, which involves reducing any concept to a set of numbers in an abstract space with multiple dimensions. By calculating the distance between these vectors, it is possible to determine the semantic distance or how related two concepts are, even if they use different words. This technique can be used in industries where keyword-based matching is currently used, such as search engines or matchmaking services. The author suggests that creating rich profiles of community members and using vector embeddings to find semantic distances between them could be a billion-dollar idea. This technique could also be applied to dating or other industries.\n",
      "\n",
      "\n",
      "\n",
      " 9 out of 18 Compressions  :  The text discusses the concept of converting unstructured data, such as text or language, into mathematically calculable data to enable distance and proximity calculations. This technology can be used in various industries, including fashion and e-commerce, to match products based on attributes or meaning. However, the accuracy of this technology depends on the accuracy of the information provided by the users. The article also discusses the need for a feedback loop to train the system and measure its success. The text emphasizes that this technology is not rocket science and can be built by near mortals in a weekend.\n",
      "\n",
      "\n",
      "\n",
      " 10 out of 18 Compressions  :  The text discusses the concept of vector embeddings and semantic search, which utilize large language models to understand the meaning behind words and phrases. This technology is becoming increasingly valuable, with companies like Pinecone and LangChain raising significant funding to develop vector databases and tools that make it easier to work with large language models. The most common language used for this work is Python, and LangChain is an open-source project that helps developers chain together different language models to create more complex applications. The article provides an example of how this technology could be used to create a travel itinerary based on a user's preferences and needs. Overall, the article suggests that vector embeddings and semantic search represent a significant opportunity for innovation and investment in the AI industry.\n",
      "\n",
      "\n",
      "\n",
      " 11 out of 18 Compressions  :  The text is a conversation between two individuals discussing the potential of chat-based interfaces enhanced by AI technology. They discuss the possibility of using AI to automate tasks such as travel bookings and lead generation. The conversation also touches on the idea of creating a personalized experience for users through the use of AI. The conversation ends with one individual disclosing that they purchased the domain chat.com for over 10 million dollars personally, as they believe that chat-based interfaces are the future. The individual also mentions their involvement in building various AI projects, including ChatSpot.ai, which aims to integrate chat and CRM software.\n",
      "\n",
      "\n",
      "\n",
      " 12 out of 18 Compressions  :  The text is a transcript of a podcast interview with Dharmesh Shah, co-founder of HubSpot, where he discusses his recent project, chatspot.ai. He explains that he built the project primarily for his own use, using OpenAI's APIs and some freelancers for front-end design skills. The project allows him to access HubSpot, look at his outlets from yesterday, ask questions, look up domain names, and see the history of a domain name. He also discusses his plans to transfer the project to be a HubSpot staffed core team, which he believes will change the world of CRM. The interviewer also asks about Dharmesh's recent purchase of the domain chat.com, to which he admits he has no concrete plans yet. The interviewer then praises Dharmesh for his enthusiasm, investment in things he likes, and content creation skills.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 13 out of 18 Compressions  :  The text is a conversation between two individuals discussing the purchase of a $10 million domain name by one of them. The speaker describes the qualities that he believes made the purchase possible, including a willingness to take risks, a belief in oneself, and the courage of one's convictions. He shares a story about a product he had envisioned but was unable to bring to market until 17 years later, when technology had caught up with his idea. He then discusses the purchase of the domain name, which he bought because it was \"cool\" and because it represented an opportunity to create something interesting and valuable. The conversation ends with a discussion of the importance of pursuing one's passions and beliefs, even in the face of uncertainty and risk.\n",
      "\n",
      "\n",
      "\n",
      " 14 out of 18 Compressions  :  The article features a conversation between two entrepreneurs, Dharmesh Shah and Sam Parr. They discuss the potential of artificial intelligence (AI) and its impact on business. Shah talks about his experience with developing a chat platform that used AI and how it could be a valuable asset to the AI community. He refers to an article by Bill Gates where he talks about the importance of natural language interfaces to software and how it will have a significant impact. Shah suggests that Sam should pursue his idea of building a community platform intersected with AI technology. He advises him to focus on his strengths and merge them with the latest technology developments. The conversation ends with a suggestion for Sam to keep pushing and not give up on his ideas.\n",
      "\n",
      "\n",
      "\n",
      " 15 out of 18 Compressions  :  The text is a conversation between two individuals discussing the strategy of incorporating new technologies into a business. One individual suggests that the company should have embraced video content early on, while the other argues that it is better to focus on what works and avoid building on shaky foundations. They discuss the risks and benefits of adopting new technologies and the importance of knowing one's strengths and weaknesses. The conversation ends with one individual offering tactical advice on how to improve the company's application process.\n",
      "\n",
      "\n",
      "\n",
      " 16 out of 18 Compressions  :  The text discusses the author's interest in AI and their approach to learning about it. They mention experimenting with various AI tools and trying to replace their existing workflow with more efficient AI workflows. The author also talks about their use of AI for creative purposes, such as designing logos and creating a brand. They also describe a project where they used AI to transcribe and summarize a podcast episode. The author emphasizes the importance of immersion in learning about AI, and credits their approach to Bill Gates' reading week. Overall, the text highlights the author's curiosity and exploration of AI, and their desire to understand its nuances and potential applications.\n",
      "\n",
      "\n",
      "\n",
      " 17 out of 18 Compressions  :  In a podcast episode, a discussion was held about using AI to create a database of every story, framework, and idea from the podcast's back catalog. The aim was to use the database to identify potential business or startup ideas. The conversation also touched on the concept of prompt engineering, which is akin to software engineering, but involves communicating with a large language model to produce desired results. The speaker mentioned buying the domain prompt.com for a seven-figure sum, with plans to use it for an idea related to prompt engineering. The discussion also touched on Balaji Srinivasan's prediction that the US dollar will crash and Bitcoin will surge to $1 million, with the speaker expressing skepticism about the probability of this outcome. Finally, the conversation emphasized the importance of creating value rather than playing arbitrage.\n",
      "\n",
      "\n",
      "\n",
      " 18 out of 18 Compressions  :  The text is a conversation between two individuals who discuss the use of web three technology and warn against taking advantage of people. They suggest that there are real problems to solve where money can be made, and that web three technology should be used creatively for bigger opportunities. The conversation ends with the host thanking the guest and expressing admiration for them.\n",
      "\n",
      "\n",
      "\n",
      "1 out of 3 Compressions: - The co-founder of HubSpot believes generative AI is the biggest tech paradigm shift since the internet\n",
      "- OpenAI is discussed as a valuable company in the next ten years, and its controversy for transforming from a non-profit to a for-profit company\n",
      "- Generative AI has potential to revolutionize industries such as healthcare and finance\n",
      "- OpenAI was initially funded by Elon Musk but later created a for-profit subsidiary to raise capital\n",
      "- The author shares personal experience using AI tools to create an intro rap for their podcast and turn their voice into a Kanye West rap\n",
      "- Generative AI has potential in creating chat-based user experiences for software and going from text to code\n",
      "- The declarative model differs from the imperative model\n",
      "- AI language model can help troubleshoot issues when creating a website\n",
      "- GPT-3 is a reasoning engine that uses a set of facts to logically answer questions\n",
      "- Potential dangers of AI include its ability to carry out harmful actions if directed by the wrong people or left to its own devices\n",
      "- The fear of AI becoming uncontrollable is not new\n",
      "- Natural language interface is becoming more advanced, which could lead to more seamless interactions with AI.\n",
      "\n",
      "\n",
      "\n",
      "2 out of 3 Compressions: - The article discusses OpenAI's recent announcement to add plugins to its chatbot, GPT, allowing third-party developers to inject proprietary data sources and other functionalities into the chatbot experience.\n",
      "- The author compares this move to the app store for the iPhone, which broadened the appeal of the device and suggests that it will open up new opportunities for various industries and businesses.\n",
      "- The article also briefly discusses vector embeddings and their potential to change the world by reducing any concept to a set of numbers in an abstract space with multiple dimensions.\n",
      "- This technique can be used in industries where keyword-based matching is currently used, such as search engines or matchmaking services, and could be a billion-dollar idea.\n",
      "- The text discusses the concept of converting unstructured data, such as text or language, into mathematically calculable data to enable distance and proximity calculations, which can be used in various industries, including fashion and e-commerce.\n",
      "- The article also discusses the need for a feedback loop to train the system and measure its success.\n",
      "- The text emphasizes that this technology is not rocket science and can be built by near mortals in a weekend.\n",
      "- The article suggests that vector embeddings and semantic search represent a significant opportunity for innovation and investment in the AI industry.\n",
      "- The text includes a conversation between two individuals discussing the potential of chat-based interfaces enhanced by AI technology, including the possibility of using AI to automate tasks such as travel bookings and lead generation.\n",
      "- The conversation also touches on the idea of creating a personalized experience for users through the use of AI.\n",
      "- The text includes a transcript of a podcast interview with Dharmesh Shah, co-founder of HubSpot, where he discusses his recent project, chatspot.ai, which allows him to access HubSpot and other functions.\n",
      "- Dharmesh also discusses his plans to transfer the project to be a HubSpot staffed core team, which he believes will change the world of CRM.\n",
      "- The interviewer also asks about Dharmesh's recent purchase of the domain chat.com, to which he admits he has no concrete plans yet.\n",
      "- The text includes a conversation between two individuals discussing the purchase of a $10 million domain name by one of them and the qualities that made the purchase possible.\n",
      "\n",
      "\n",
      "\n",
      "3 out of 3 Compressions: - The article features a conversation between two entrepreneurs, Dharmesh Shah and Sam Parr, discussing the potential of artificial intelligence (AI) and its impact on business.\n",
      "- Shah talks about his experience with developing a chat platform that used AI and how it could be a valuable asset to the AI community.\n",
      "- They discuss the risks and benefits of adopting new technologies and the importance of knowing one's strengths and weaknesses.\n",
      "- The author of another text discusses their interest in AI and their approach to learning about it, experimenting with various AI tools and using AI for creative purposes.\n",
      "- In a podcast episode, a discussion was held about using AI to create a database of every story, framework, and idea from the podcast's back catalog to identify potential business or startup ideas.\n",
      "- The conversation also touched on the concept of prompt engineering and the prediction that the US dollar will crash and Bitcoin will surge to $1 million.\n",
      "- In another conversation, two individuals warn against taking advantage of people and suggest using web three technology creatively for bigger opportunities.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey there! I've been reading up on the latest advancements in artificial intelligence (AI) and I'm excited to share some of the most interesting insights with you. According to the co-founder of HubSpot, generative AI is the biggest tech paradigm shift since the internet. OpenAI is a valuable company to watch in the next ten years, despite its controversy for transforming from a non-profit to a for-profit company. \n",
      "\n",
      "Generative AI has the potential to revolutionize industries such as healthcare and finance. I even had a personal experience using AI tools to create an intro rap for my podcast and turn my voice into a Kanye West rap. \n",
      "\n",
      "AI language models are becoming more advanced and have the potential to create chat-based user experiences for software and go from text to code. The declarative model differs from the imperative model and AI language models can help troubleshoot issues when creating a website. \n",
      "\n",
      "GPT-3 is a reasoning engine that uses a set of facts to logically answer questions. However, there are potential dangers of AI, including its ability to carry out harmful actions if directed by the wrong people or left to its own devices. The fear of AI becoming uncontrollable is not new. \n",
      "\n",
      "OpenAI's recent announcement to add plugins to its chatbot, GPT, allowing third-party developers to inject proprietary data sources and other functionalities into the chatbot experience, is a significant move that will open up new opportunities for various industries and businesses. \n",
      "\n",
      "Vector embeddings have the potential to change the world by reducing any concept to a set of numbers in an abstract space with multiple dimensions. This technique can be used in industries where keyword-based matching is currently used, such as search engines or matchmaking services, and could be a billion-dollar idea. \n",
      "\n",
      "The article also discusses the concept of converting unstructured data, such as text or language, into mathematically calculable data to enable distance and proximity calculations, which can be used in various industries, including fashion and e-commerce. \n",
      "\n",
      "In a podcast episode, a discussion was held about using AI to create a database of every story, framework, and idea from the podcast's back catalog to identify potential business or startup ideas. The conversation also touched on the concept of prompt engineering and the prediction that the US dollar will crash and Bitcoin will surge to $1 million. \n",
      "\n",
      "Overall, the potential of AI is limitless, and it's exciting to see how it will continue to shape the future of various industries in the years to come.\n",
      "Text-to-speech conversion successful\n"
     ]
    }
   ],
   "source": [
    "def open_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "        return infile.read()\n",
    "\n",
    "def save_file(filepath, content):\n",
    "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(content)\n",
    "\n",
    "openai.api_key = open_file('openaiapikey.txt')\n",
    "\n",
    "chatbot5 = \" \"\n",
    "\n",
    "elapikey = open_file('elabapikey.txt')\n",
    "\n",
    "conversation = []\n",
    "\n",
    "#THIS FUNCTION USES ChatGPT API TO SUMMARIZE (CHEAPER)\n",
    "def gpt_3(prompt, engine='text-davinci-003', temp=0.6, top_p=1.0, tokens=1000, freq_pen=0.0, pres_pen=0.0, stop=['asdfasdf', 'asdasdf']):\n",
    "    max_retry = 5\n",
    "    retry = 0\n",
    "    prompt = prompt.encode(encoding='ASCII',errors='ignore').decode()\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                engine=engine,\n",
    "                prompt=prompt,\n",
    "                temperature=temp,\n",
    "                max_tokens=tokens,\n",
    "                top_p=top_p,\n",
    "                frequency_penalty=freq_pen,\n",
    "                presence_penalty=pres_pen,\n",
    "                stop=stop)\n",
    "            text = response['choices'][0]['text'].strip()\n",
    "            return text\n",
    "        except Exception as oops:\n",
    "            retry += 1\n",
    "            if retry >= max_retry:\n",
    "                return \"GPT3 error: %s\" % oops\n",
    "            print('Error communicating with OpenAI:', oops)\n",
    "            sleep(1)\n",
    "            \n",
    "def chatgpt3(userinput, temperature=0.6, frequency_penalty=0, presence_penalty=0):\n",
    "    max_retry = 6\n",
    "    retry = 0\n",
    "    messagein = [\n",
    "        {\"role\": \"user\", \"content\": userinput },\n",
    "        {\"role\": \"system\", \"content\": chatbot5}]\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=temperature,\n",
    "                frequency_penalty=frequency_penalty,\n",
    "                presence_penalty=presence_penalty,\n",
    "                messages=messagein\n",
    "            )\n",
    "            text = response['choices'][0]['message']['content']\n",
    "            return text\n",
    "        except Exception as oops:\n",
    "            retry += 1\n",
    "            if retry >= max_retry:\n",
    "                return \"GPT3 error: %s\" % oops\n",
    "            print('Error communicating with OpenAI:', oops)\n",
    "            sleep(1)          \n",
    "\n",
    "\n",
    "# paste the YouTube video link here\n",
    "video_url = open_file(\"URL.txt\")\n",
    "\n",
    "# create a YouTube object\n",
    "youtube = YouTube(video_url)\n",
    "\n",
    "# get the highest resolution video stream\n",
    "video_stream = youtube.streams.get_highest_resolution()\n",
    "\n",
    "#Your Pathfolder\n",
    "pathfolder = '/Users/akram/Desktop/AI/Langchain Projects/Podcast Summarizer/'\n",
    "   \n",
    "# download the video to the pathfolder directory with the filename ytvideo.mp4\n",
    "video_file_path = video_stream.download(output_path=pathfolder, filename='ytvideo.mp4')\n",
    "\n",
    "# split the audio from the video file into 10-minute segments\n",
    "segment_duration = 10 * 60 * 1000  # 10 minutes in milliseconds\n",
    "audio = AudioSegment.from_file(video_file_path, \"mp4\")\n",
    "num_segments = int(len(audio) / segment_duration) + 1\n",
    "for i in range(num_segments):\n",
    "    segment = audio[i*segment_duration:(i+1)*segment_duration]\n",
    "    segment_file_path = os.path.join(pathfolder, f\"segment_{i}.mp3\")\n",
    "    segment.export(segment_file_path, format='mp3')\n",
    "\n",
    "    # transcribe each segment of audio separately\n",
    "    transcripts = []\n",
    "for i in range(num_segments):\n",
    "    segment_path = os.path.join(pathfolder, f\"segment_{i}.mp3\")\n",
    "    with open(segment_path, \"rb\") as f:\n",
    "        transcript = openai.Audio.transcribe(\"whisper-1\", f)\n",
    "        print(transcript)\n",
    "        transcripts.append(transcript.text)\n",
    "\n",
    "    # concatenate the transcripts and save to a file in the same directory as the video file\n",
    "    full_transcript = \"\\n\".join(transcripts)\n",
    "    save_file(os.path.join(pathfolder, \"podscript.txt\"), full_transcript)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # get a list of all text files in the specified folder\n",
    "    files = ['/Users/akram/Desktop/AI/Langchain Projects/Podcast Summarizer/podscript.txt']\n",
    "    \n",
    "    # initialize an empty string to store the contents of all the text files\n",
    "    alltext = \"\"\n",
    "    \n",
    "\n",
    "    # iterate over the list of files\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as infile:  # open the file\n",
    "            alltext += infile.read()  # read the contents of the file and append it to the alltext string\n",
    "    chunks = textwrap.wrap(alltext, 5000)\n",
    "    result = list()\n",
    "    count = 0\n",
    "    \n",
    "    #write a summary\n",
    "    for chunk in chunks:\n",
    "        count = count + 1\n",
    "        prompt = open_file('prompt.txt').replace('<SUMMARY>', chunk)\n",
    "        prompt = prompt.encode(encoding='ASCII',errors='ignore').decode()\n",
    "        summary = chatgpt3(prompt)\n",
    "        print('\\n\\n\\n', count, 'out of', len(chunks), 'Compressions', ' : ', summary)\n",
    "        result.append(summary)\n",
    "        save_file(\"podsummary.txt\", '\\n\\n'.join(result))\n",
    "\n",
    "# Split the contents of pfdsummary.txt into chunks with a textwrap of 3000\n",
    "    with open(\"podsummary.txt\", 'r', encoding='utf-8') as infile:\n",
    "        summary = infile.read()\n",
    "        chunks = textwrap.wrap(summary, 5000)\n",
    "\n",
    "    #Initialize empty lists to store the results\n",
    "    result = []\n",
    "    result2 = []\n",
    "\n",
    "    #WRITE NOTES FROM CHUNKS\n",
    "    for i, chunk in enumerate(chunks):\n",
    "         #Read the contents of prompt2.txt\n",
    "        with open(\"prompt2.txt\", 'r', encoding='utf-8') as infile:\n",
    "            prompt = infile.read()\n",
    "\n",
    "        # Replace the placeholder in the prompt with the current chunk\n",
    "        prompt = prompt.replace(\"<NOTES>\", chunk)\n",
    "\n",
    "        # Run the chunk through the gpt_3 function\n",
    "        notes = chatgpt3(prompt)\n",
    "        \n",
    "        #WRITE A SUMMARY FROM NOTES\n",
    "        keytw = open_file('prompt6.txt').replace('<NOTES>', chunk)\n",
    "        keytw2 = chatgpt3(keytw)\n",
    "\n",
    "\n",
    "        # Print the result\n",
    "        print(f\"\\n\\n\\n{i+1} out of {len(chunks)} Compressions: {notes}\")\n",
    "\n",
    "         #Append the results to the lists\n",
    "        result.append(notes)\n",
    "        result2.append(keytw2)\n",
    "\n",
    "\n",
    "    #Save the results to a file\n",
    "    with open(\"notes.txt\", 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(\"\\n\\n\".join(result))\n",
    "        \n",
    "    with open(\"notessum.txt\", 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(\"\\n\\n\".join(result2))\n",
    "\n",
    "    #SUMMARY OF NOTES\n",
    "    sumnotes = open_file(\"notes.txt\")\n",
    "    \n",
    "\n",
    "    #WRITE A SYNOPSIS\n",
    "    keytw = open_file('prompt5.txt').replace('<NOTES>', sumnotes)\n",
    "    keytw2 = chatgpt3(keytw)\n",
    "    print(keytw2)\n",
    "    save_file(\"synopsis3.txt\", keytw2)\n",
    "    \n",
    "    #ElvenLabs Voice\n",
    "    url = 'https://api.elevenlabs.io/v1/text-to-speech/EXAVITQu4vr4xnSDxMaL'\n",
    "    headers = {\n",
    "        'accept': 'audio/mpeg',\n",
    "        'xi-api-key': elapikey,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    data = {\n",
    "        'text': keytw2,\n",
    "        'voice_settings': {\n",
    "            'stability': 0.6,\n",
    "            'similarity_boost': 0.85\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        with open('voicesum.mp3', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print('Text-to-speech conversion successful')\n",
    "    else:\n",
    "        print('Error:', response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPjwdRgKDdBD0Fwr1mE5OJk",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
